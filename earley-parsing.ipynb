{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Earley parser\n",
    "All code is by Wikler Aziz unless noted explicitly. New are: earley_axioms, predict and earley.\n",
    "\n",
    "This notebook essentially builts on the notebook lab-cky.ipynb, and copied code from lab-cfg.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cfg import read_grammar_rules, WCFG\n",
    "from rule import Rule\n",
    "from symbol import is_terminal, is_nonterminal, make_symbol\n",
    "from collections import defaultdict\n",
    "from item import Item\n",
    "from agenda import Agenda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cky_axioms(cfg, sentence):\n",
    "    \"\"\"\n",
    "    :params cfg: a context-free grammar (an instance of WCFG)\n",
    "    :params sentence: the input sentence (as a list or tuple)\n",
    "    :returns: a list of items\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for rule in cfg:\n",
    "        for i in range(len(sentence)):\n",
    "            items.append(Item(rule, [i]))\n",
    "    return items\n",
    "\n",
    "def earley_axioms(cfg, sentence, start):\n",
    "    \"\"\"\n",
    "    Author: Daan\n",
    "    Axioms for Earley.\n",
    "\n",
    "    Inference rule:\n",
    "        -------------------- (S -> alpha) in cfgs\n",
    "        [S -> * alpha, [0]] \n",
    "\n",
    "    :param cfg: a context-free grammar (an instance of WCFG)\n",
    "    :param sentence: the input sentence (as a list or tuple)\n",
    "    :returns: a list of items that are Earley axioms  \n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for rule in cfg.get(start):\n",
    "        items.append(Item(rule, [0]))\n",
    "    return items\n",
    "\n",
    "def predict(cfg, item):\n",
    "    \"\"\"\n",
    "    Author: Daan\n",
    "    Prediction for Earley.\n",
    "\n",
    "    Inference rule:\n",
    "        -------------------- (SS -> alpha) in cfgs\n",
    "        [S -> * alpha, [0]] \n",
    "\n",
    "    :param cfg: a context-free grammar (an instance of WCFG)\n",
    "    :param item: an active Item\n",
    "    :returns: a list of predicted Items or None  \n",
    "    \"\"\"\n",
    "    items = []\n",
    "    rules = cfg.get(item.next)\n",
    "    for rule in rules:\n",
    "            items.append(Item(rule, [item.dot]))\n",
    "    return items\n",
    "\n",
    "def scan(item, sentence):\n",
    "    \"\"\"\n",
    "    Scan a terminal (compatible with CKY and Earley).\n",
    "    \n",
    "    Inference rule:\n",
    "    \n",
    "        [X -> alpha * x beta, [i ... j]]\n",
    "        ------------------------------------    sentence[j] == x\n",
    "        [X -> alpha x * beta, [i ... j + 1]]\n",
    "    \n",
    "    :param item: an active Item\n",
    "    :param sentence: a list/tuple of terminals\n",
    "    :returns: an Item or None\n",
    "    \"\"\"\n",
    "    assert is_terminal(item.next), 'Only terminal symbols can be scanned, got %s' % item.next\n",
    "    if item.dot < len(sentence) and sentence[item.dot] == item.next:\n",
    "        return item.advance(item.dot + 1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def complete(item, agenda):\n",
    "    \"\"\"\n",
    "    Move dot over nonterminals (compatible with CKY and Earley).\n",
    "    \n",
    "    Inference rule:\n",
    "    \n",
    "        [X -> alpha * Y beta, [i ... k]] [Y -> gamma *, [k ... j]]\n",
    "        ----------------------------------------------------------\n",
    "                 [X -> alpha Y * beta, [i ... j]]\n",
    "                 \n",
    "    :param item: an active Item.\n",
    "        if `item` is complete, we advance the dot of incomplete passive items to `item.dot`\n",
    "        otherwise, we check whether we know a set of positions J = {j1, j2, ..., jN} such that we can\n",
    "        advance this item's dot to.\n",
    "    :param agenda: an instance of Agenda\n",
    "    :returns: a list of items\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    if item.is_complete():\n",
    "        # advance the dot for incomplete items waiting for item.lhs spanning from item.start\n",
    "        for incomplete in agenda.waiting(item.lhs, item.start):\n",
    "            items.append(incomplete.advance(item.dot))\n",
    "    else:\n",
    "        # look for completions of item.next spanning from item.dot\n",
    "        ends = set()\n",
    "        for complete in agenda.complete(item.next, item.dot):\n",
    "            ends.add(complete.dot)\n",
    "        # advance the dot of the input item for each position that complete a span\n",
    "        for end in ends:\n",
    "            items.append(item.advance(end))\n",
    "    return items\n",
    "\n",
    "\n",
    "def make_forest(complete_items):\n",
    "    \"\"\"\n",
    "    Turn complete items into a WCFG.\n",
    "    \n",
    "    :param complete_items: complete items (iterable)\n",
    "    :returns: a WCFG\n",
    "    \"\"\"\n",
    "    forest = WCFG()\n",
    "    for item in complete_items:\n",
    "        lhs = make_symbol(item.lhs, item.start, item.dot)\n",
    "        rhs = []\n",
    "        for i, sym in enumerate(item.rule.rhs):\n",
    "            rhs.append(make_symbol(sym, item.state(i), item.state(i + 1)))\n",
    "        forest.add(Rule(lhs, rhs, item.rule.prob))\n",
    "    return forest\n",
    "\n",
    "def make_chart(complete_items, n):\n",
    "    chart = [[defaultdict(list) for j in range(n)] for i in range(n)] # n by n matrix with edges\n",
    "    for item in complete_items:\n",
    "        chart[item.start][item.dot][item.lhs].append((item.rule, item.dots_))\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CKY parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cky(cfg, sentence):\n",
    "    A = Agenda()\n",
    "    for item in cky_axioms(cfg, sentence):\n",
    "        A.push(item)\n",
    "    while A:\n",
    "        item = A.pop()\n",
    "        if item.is_complete() or is_nonterminal(item.next):\n",
    "            for new in complete(item, A):\n",
    "                A.push(new)\n",
    "        else:\n",
    "            new = scan(item, sentence)\n",
    "            if new is not None:\n",
    "                A.push(new)\n",
    "        A.make_passive(item)\n",
    "    return make_forest(A.itercomplete())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earley parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def earley(cfg, sentence, start):\n",
    "    \"\"\"\n",
    "    Author: Daan\n",
    "    \"\"\"\n",
    "    A = Agenda()\n",
    "    for item in earley_axioms(cfg, sentence, start):\n",
    "        A.push(item)\n",
    "    while len(A) > 0:\n",
    "        item = A.pop()\n",
    "        if item.is_complete() or is_nonterminal(item.next):\n",
    "            for new in predict(cfg, item):\n",
    "                A.push(new)\n",
    "            for new in complete(item, A):\n",
    "                A.push(new)\n",
    "        else:\n",
    "            new = scan(item, sentence)\n",
    "            if new is not None:\n",
    "                A.push(new)\n",
    "        A.make_passive(item)\n",
    "    return make_forest(A.itercomplete())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing parsers\n",
    "\n",
    "We can compare the Earley and CKY parsers on a number of different grammars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with this we can plot trees\n",
    "from util import make_nltk_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first grammar is the grammar of arithmetic expressions involving sum an multiplication. This grammar is taken from Earley's original 1970 paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T] -> [P] (0.5)\n",
      "[T] -> [T] * [P] (0.5)\n",
      "[E] -> [T] (0.5)\n",
      "[E] -> [E] + [T] (0.5)\n",
      "[P] -> a (1.0)\n"
     ]
    }
   ],
   "source": [
    "G1 = WCFG(read_grammar_rules(open('examples/arithmetic', 'r')))\n",
    "print G1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we analyze an ambiguous version of that grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T] -> [P] (0.5)\n",
      "[T] -> [T] * [P] (0.4)\n",
      "[T] -> [T] + [P] (0.1)\n",
      "[E] -> [T] (0.5)\n",
      "[E] -> [E] + [T] (0.45)\n",
      "[E] -> [E] * [T] (0.05)\n",
      "[P] -> a (1.0)\n"
     ]
    }
   ],
   "source": [
    "G2 = WCFG(read_grammar_rules(open('examples/ambiguous', 'r')))\n",
    "print G2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we consider a grammar that produces natural language sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NN] -> mouse (0.33)\n",
      "[NN] -> cat (0.33)\n",
      "[NN] -> dog (0.34)\n",
      "[JJ] -> big (0.5)\n",
      "[JJ] -> black (0.5)\n",
      "[DT] -> the (0.5)\n",
      "[DT] -> a (0.5)\n",
      "[NPBAR] -> [JJ] [NN] (0.5)\n",
      "[NPBAR] -> [JJ] [NPBAR] (0.5)\n",
      "[VP] -> [VB] [NP] (1.0)\n",
      "[S] -> [NP] [VP] (1.0)\n",
      "[VB] -> chased (0.5)\n",
      "[VB] -> ate (0.5)\n",
      "[NP] -> [DT] [NN] (0.5)\n",
      "[NP] -> [DT] [NPBAR] (0.5)\n"
     ]
    }
   ],
   "source": [
    "G3 = WCFG(read_grammar_rules(open('examples/hdp-pcfg-grammar', 'r')))\n",
    "print G3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_sample(grammar, items=('[E]',)):\n",
    "    \"\"\"\n",
    "    Given a grammar returns a sentence from it using\n",
    "    the probabilities specfied in the grammar.\n",
    "    :param items: call the function with (start,) where \n",
    "                  start is the start symbol of the grammar\n",
    "    :returns: a sentence from the language as a list\n",
    "    \"\"\"\n",
    "    frags = []\n",
    "    for item in items:\n",
    "        if is_nonterminal(item):\n",
    "            productions = grammar.get(item)\n",
    "            ps = [production.prob for production in productions]\n",
    "            random_index = np.argmax(np.random.multinomial(1, ps, size=1))\n",
    "            prod = productions[random_index]\n",
    "            frags.extend(generate_sample(grammar, items=prod.rhs))\n",
    "        else:\n",
    "            frags.append(item)\n",
    "    return frags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', '*', 'a', '+', 'a']\n"
     ]
    }
   ],
   "source": [
    "sentence1 = generate_sample(G1)\n",
    "print sentence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:2-3] -> [T:2-3] (0.5)\n",
      "[E:4-5] -> [T:4-5] (0.5)\n",
      "[T:0-3] -> [T:0-1] * [P:2-3] (0.4)\n",
      "[T:0-5] -> [T:0-3] + [P:4-5] (0.1)\n",
      "[E:0-5] -> [E:0-3] + [T:4-5] (0.45)\n",
      "[E:0-5] -> [T:0-5] (0.5)\n",
      "[E:0-5] -> [E:0-1] * [T:2-5] (0.05)\n",
      "[T:0-1] -> [P:0-1] (0.5)\n",
      "[E:0-1] -> [T:0-1] (0.5)\n",
      "[E:0-3] -> [E:0-1] * [T:2-3] (0.05)\n",
      "[E:0-3] -> [T:0-3] (0.5)\n",
      "[E:2-5] -> [T:2-5] (0.5)\n",
      "[E:2-5] -> [E:2-3] + [T:4-5] (0.45)\n",
      "[P:0-1] -> a (1.0)\n",
      "[T:4-5] -> [P:4-5] (0.5)\n",
      "[P:2-3] -> a (1.0)\n",
      "[T:2-5] -> [T:2-3] + [P:4-5] (0.1)\n",
      "[T:2-3] -> [P:2-3] (0.5)\n",
      "[P:4-5] -> a (1.0)\n",
      "19\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "goal = make_symbol('[E]', 0, len(sentence1))\n",
    "\n",
    "forest = cky(G1, sentence1)\n",
    "print forest\n",
    "print len(forest)\n",
    "\n",
    "forest = earley(G1, sentence1, goal)\n",
    "print forest\n",
    "print len(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:2-3] -> [T:2-3] (0.5)\n",
      "[E:4-5] -> [T:4-5] (0.5)\n",
      "[T:0-3] -> [T:0-1] * [P:2-3] (0.4)\n",
      "[T:0-5] -> [T:0-3] + [P:4-5] (0.1)\n",
      "[E:0-5] -> [E:0-3] + [T:4-5] (0.45)\n",
      "[E:0-5] -> [T:0-5] (0.5)\n",
      "[E:0-5] -> [E:0-1] * [T:2-5] (0.05)\n",
      "[T:0-1] -> [P:0-1] (0.5)\n",
      "[E:0-1] -> [T:0-1] (0.5)\n",
      "[E:0-3] -> [E:0-1] * [T:2-3] (0.05)\n",
      "[E:0-3] -> [T:0-3] (0.5)\n",
      "[E:2-5] -> [T:2-5] (0.5)\n",
      "[E:2-5] -> [E:2-3] + [T:4-5] (0.45)\n",
      "[P:0-1] -> a (1.0)\n",
      "[T:4-5] -> [P:4-5] (0.5)\n",
      "[P:2-3] -> a (1.0)\n",
      "[T:2-5] -> [T:2-3] + [P:4-5] (0.1)\n",
      "[T:2-3] -> [P:2-3] (0.5)\n",
      "[P:4-5] -> a (1.0)\n",
      "19\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "goal = make_symbol('[E]', 0, len(sentence1))\n",
    "\n",
    "forest = cky(G2, sentence1)\n",
    "print forest\n",
    "print len(forest)\n",
    "\n",
    "forest = earley(G2, sentence1, goal)\n",
    "print forest\n",
    "print len(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'black', 'dog', 'chased', 'the', 'big', 'mouse']\n"
     ]
    }
   ],
   "source": [
    "sentence3 = generate_sample(G3, items=('[S]',))\n",
    "print sentence3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NN:6-7] -> mouse (0.33)\n",
      "[NN:2-3] -> dog (0.34)\n",
      "[NP:0-3] -> [DT:0-1] [NPBAR:1-3] (0.5)\n",
      "[DT:0-1] -> the (0.5)\n",
      "[S:0-7] -> [NP:0-3] [VP:3-7] (1.0)\n",
      "[NPBAR:5-7] -> [JJ:5-6] [NN:6-7] (0.5)\n",
      "[NPBAR:1-3] -> [JJ:1-2] [NN:2-3] (0.5)\n",
      "[DT:4-5] -> the (0.5)\n",
      "[VP:3-7] -> [VB:3-4] [NP:4-7] (1.0)\n",
      "[VB:3-4] -> chased (0.5)\n",
      "[NP:4-7] -> [DT:4-5] [NPBAR:5-7] (0.5)\n",
      "[JJ:1-2] -> black (0.5)\n",
      "[JJ:5-6] -> big (0.5)\n",
      "13\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "goal = make_symbol('[S]', 0, len(sentence3))\n",
    "\n",
    "forest = cky(G3, sentence3)\n",
    "print forest\n",
    "print len(forest)\n",
    "\n",
    "forest = earley(G3, sentence3, goal)\n",
    "print forest\n",
    "print len(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
