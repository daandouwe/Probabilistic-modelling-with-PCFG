{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The HDP-PCFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rule import Rule\n",
    "from cfg import WCFG, read_grammar_rules\n",
    "from parser import cky\n",
    "from earley import earley\n",
    "from symbol import make_symbol, is_nonterminal, is_terminal\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from InsideOutside import inside, outside, inside_outside, EM, plot_EM\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(grammar, items=('[E]',)):\n",
    "    \"\"\"\n",
    "    Given a grammar returns a sentence from it using\n",
    "    the probabilities specfied in the grammar.\n",
    "    :param items: call the function with (start,) where \n",
    "                  start is the start symbol of the grammar\n",
    "    :returns: a sentence from the language as a list\n",
    "    \"\"\"\n",
    "    frags = []\n",
    "    for item in items:\n",
    "        if is_nonterminal(item):\n",
    "            productions = grammar.get(item)\n",
    "            ps = [production.prob for production in productions]\n",
    "            random_index = np.argmax(np.random.multinomial(1, ps, size=1))\n",
    "            prod = productions[random_index]\n",
    "            frags.extend(generate_sample(grammar, items=prod.rhs))\n",
    "        else:\n",
    "            frags.append(item)\n",
    "    return frags\n",
    "\n",
    "def generate_corpus(grammar, n, start=('[E]',)):\n",
    "    \"\"\"\n",
    "    Generates a corpus using the grammar\n",
    "    :param n: size of the corpus\n",
    "    :params: same a s generate corpus\n",
    "    :returns: a corpus in the form of a list\n",
    "    \"\"\"\n",
    "    return [generate_sample(grammar, items=start) for i in range(n)]\n",
    "\n",
    "def initialize(grammar, alpha=20.0):\n",
    "    \"\"\"\n",
    "    Takes a grammar and returns that grammar with \n",
    "    the probabilities replaced by random probabilities\n",
    "    generated from a Dirichlet distribution.\n",
    "    :param: alpha is the Dirichlet concentration parameter\n",
    "    \"\"\"\n",
    "    init_grammar = WCFG()\n",
    "    for nonterminal in grammar.nonterminals:\n",
    "        rules = grammar.get(nonterminal)\n",
    "        init_prob = np.random.dirichlet(len(rules)*[alpha])\n",
    "        for i, rule in enumerate(rules):\n",
    "            init_grammar.add(Rule(rule.lhs, rule.rhs, init_prob[i]))\n",
    "    return init_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counting(forest, start):  # acyclic hypergraph\n",
    "    N = dict()\n",
    "    \n",
    "    def get_count(symbol):\n",
    "        w = N.get(symbol, None)\n",
    "        if w is not None:\n",
    "            return w\n",
    "        incoming = forest.get(symbol, set())\n",
    "        if len(incoming) == 0:  # terminals have already been handled, this must be a nonterminal dead end\n",
    "            N[symbol] = w\n",
    "            return 0\n",
    "        w = 0\n",
    "        for rule in incoming:\n",
    "            k = 1\n",
    "            for child in rule.rhs:\n",
    "                k *= get_count(child)\n",
    "            w += k\n",
    "        N[symbol] = w\n",
    "        return w\n",
    "    \n",
    "    # handles terminals\n",
    "    for sym in forest.terminals:\n",
    "        N[sym] = 1\n",
    "    # handles nonterminals\n",
    "    #for sym in forest.nonterminals:\n",
    "    #    get_inside(sym)\n",
    "    get_count(start)\n",
    "        \n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def get_instances(rule, forest):\n",
    "    \"\"\"\n",
    "    Given a rule\n",
    "    \n",
    "    A -> B C \n",
    "    \n",
    "    get_instances collects all instances of rules of the form\n",
    "    \n",
    "    [A:i-j] -> [B:i-k] [C:k-j] \n",
    "    \n",
    "    from the forest and returns them in a list.\n",
    "    \"\"\"\n",
    "    instances = []\n",
    "    for r in forest:\n",
    "        if r.lhs[1] == rule.lhs[1] and len(r.rhs)==len(rule.rhs):\n",
    "            test = []\n",
    "            for i in range(len(r.rhs)):\n",
    "                try:\n",
    "                    # if for example r.rhs[i] = '[A]' \n",
    "                    v = r.rhs[i][1] == rule.rhs[i][1]\n",
    "                    test.append(v)\n",
    "                except IndexError:\n",
    "                    # if for example r.rhs[i] = '*' \n",
    "                    v = r.rhs[i][0] == rule.rhs[i][0]\n",
    "                    test.append(v)\n",
    "            if np.all(test):\n",
    "                instances.append(r)\n",
    "    return instances\n",
    "\n",
    "def inside_outside(training_sents, grammar, start_sym='[E]'):\n",
    "    f = defaultdict(float)\n",
    "    for sent in training_sents:\n",
    "        forest = cky(grammar, sent)\n",
    "        goal = make_symbol(start_sym, 0, len(sent))\n",
    "        I = inside(forest, goal)\n",
    "        O = outside(forest, goal, I)     \n",
    "        for rule in grammar:\n",
    "            w = 0.0\n",
    "            for instance in get_instances(rule, forest):\n",
    "                k = rule.prob\n",
    "                k *= O[instance.lhs]\n",
    "                for child in instance.rhs:\n",
    "                    try:\n",
    "                        alpha = I[child]\n",
    "                    except KeyError:\n",
    "                        # same solution as in outside\n",
    "                        alpha = 0.0\n",
    "                    k *= alpha\n",
    "                w += k\n",
    "            f[rule] += w/I[goal]\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NN] -> mouse (0.33)\n",
      "[NN] -> cat (0.33)\n",
      "[NN] -> dog (0.34)\n",
      "[JJ] -> big (0.5)\n",
      "[JJ] -> black (0.5)\n",
      "[DT] -> the (0.5)\n",
      "[DT] -> a (0.5)\n",
      "[NPBAR] -> [JJ] [NN] (0.5)\n",
      "[NPBAR] -> [JJ] [NPBAR] (0.5)\n",
      "[VP] -> [VB] [NP] (1.0)\n",
      "[S] -> [NP] [VP] (1.0)\n",
      "[VB] -> chased (0.5)\n",
      "[VB] -> ate (0.5)\n",
      "[NP] -> [DT] [NN] (0.5)\n",
      "[NP] -> [DT] [NPBAR] (0.5)\n",
      "[['a', 'cat', 'chased', 'a', 'big', 'cat'], ['the', 'big', 'mouse', 'chased', 'a', 'dog'], ['the', 'big', 'mouse', 'ate', 'a', 'big', 'black', 'mouse'], ['a', 'mouse', 'chased', 'the', 'dog'], ['a', 'big', 'black', 'dog', 'chased', 'a', 'dog'], ['the', 'mouse', 'chased', 'the', 'black', 'dog'], ['the', 'dog', 'ate', 'the', 'big', 'mouse'], ['the', 'mouse', 'ate', 'a', 'big', 'big', 'black', 'big', 'cat'], ['the', 'big', 'black', 'big', 'dog', 'chased', 'the', 'big', 'black', 'dog'], ['the', 'black', 'cat', 'ate', 'a', 'black', 'big', 'dog']]\n"
     ]
    }
   ],
   "source": [
    "hdp_pcfg = WCFG(read_grammar_rules(open('examples/hdp-pcfg-grammar', 'r')))\n",
    "print hdp_pcfg\n",
    "hdp_corpus = generate_corpus(hdp_pcfg, 10, start=('[S]',))\n",
    "print hdp_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "sentence = hdp_corpus[1]\n",
    "for sentence in hdp_corpus:\n",
    "    cky_forest = cky(hdp_pcfg, sentence)\n",
    "#     print cky_forest\n",
    "    goal = make_symbol('[S]', 0, len(sentence))\n",
    "    print counting(cky_forest, goal)[goal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NN] -> mouse (0.33)\n",
      "[NN] -> cat (0.33)\n",
      "[NN] -> dog (0.34)\n",
      "[JJ] -> big (0.5)\n",
      "[JJ] -> black (0.5)\n",
      "[DT] -> the (0.5)\n",
      "[DT] -> a (0.5)\n",
      "[NPBAR] -> [JJ] [NN] (0.5)\n",
      "[NPBAR] -> [JJ] [NPBAR] (0.5)\n",
      "[VP] -> [VB] [NP] (1.0)\n",
      "[S] -> [NP] [VP] (1.0)\n",
      "[VB] -> chased (0.5)\n",
      "[VB] -> ate (0.5)\n",
      "[NP] -> [DT] [NN] (0.5)\n",
      "[NP] -> [DT] [NPBAR] (0.5)\n",
      "defaultdict(<type 'float'>, {[NN] -> mouse (0.33): 15.73529411764706, [DT] -> the (0.5): 11.0, [VP] -> [VB] [NP] (1.0): 10.0, [JJ] -> black (0.5): 8.0, [NN] -> cat (0.33): 4.0, [NPBAR] -> [JJ] [NPBAR] (0.5): 21.0, [NN] -> dog (0.34): 16.212121212121215, [S] -> [NP] [VP] (1.0): 10.0, [JJ] -> big (0.5): 13.0, [NPBAR] -> [JJ] [NN] (0.5): 21.0, [DT] -> a (0.5): 9.0, [VB] -> chased (0.5): 6.0, [NP] -> [DT] [NN] (0.5): 20.0, [VB] -> ate (0.5): 4.0, [NP] -> [DT] [NPBAR] (0.5): 20.0})\n",
      "['a', 'cat', 'chased', 'a', 'big', 'cat']\n",
      "['the', 'big', 'mouse', 'chased', 'a', 'dog']\n",
      "['the', 'big', 'mouse', 'ate', 'a', 'big', 'black', 'mouse']\n",
      "['a', 'mouse', 'chased', 'the', 'dog']\n",
      "['a', 'big', 'black', 'dog', 'chased', 'a', 'dog']\n",
      "['the', 'mouse', 'chased', 'the', 'black', 'dog']\n",
      "['the', 'dog', 'ate', 'the', 'big', 'mouse']\n",
      "['the', 'mouse', 'ate', 'a', 'big', 'big', 'black', 'big', 'cat']\n",
      "['the', 'big', 'black', 'big', 'dog', 'chased', 'the', 'big', 'black', 'dog']\n",
      "['the', 'black', 'cat', 'ate', 'a', 'black', 'big', 'dog']\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print hdp_pcfg\n",
    "f = inside_outside(hdp_corpus, hdp_pcfg, start_sym='[S]')\n",
    "print f\n",
    "\n",
    "s = 0\n",
    "for sent in hdp_corpus:\n",
    "    print sent\n",
    "    s += sum(map(lambda x : x=='chased', sent))\n",
    "print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S] -> [X1] [X1] (0.25)\n",
      "[S] -> [X2] [X2] (0.25)\n",
      "[S] -> [X3] [X3] (0.25)\n",
      "[S] -> [X4] [X4] (0.25)\n",
      "[X3] -> a3 (0.25)\n",
      "[X3] -> b3 (0.25)\n",
      "[X3] -> c3 (0.25)\n",
      "[X3] -> d3 (0.25)\n",
      "[X2] -> a2 (0.25)\n",
      "[X2] -> b2 (0.25)\n",
      "[X2] -> c2 (0.25)\n",
      "[X2] -> d2 (0.25)\n",
      "[X4] -> a4 (0.25)\n",
      "[X4] -> b4 (0.25)\n",
      "[X4] -> c4 (0.25)\n",
      "[X4] -> d4 (0.25)\n",
      "[X1] -> a1 (0.25)\n",
      "[X1] -> b1 (0.25)\n",
      "[X1] -> c1 (0.25)\n",
      "[X1] -> d1 (0.25)\n",
      "[['a4', 'a4'], ['d1', 'c1'], ['b4', 'd4'], ['c2', 'd2'], ['c4', 'd4'], ['d4', 'c4'], ['d4', 'c4'], ['b2', 'b2'], ['c3', 'd3'], ['c3', 'c3']]\n"
     ]
    }
   ],
   "source": [
    "synthetic = WCFG(read_grammar_rules(open('examples/synthetic', 'r')))\n",
    "print synthetic\n",
    "synthetic_corpus = generate_corpus(synthetic, 10, start=('[S]',))\n",
    "print synthetic_corpus\n",
    "# print sum(map(lambda (x,y): x==y, synthetic_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X3:0-1] -> c3 (0.25)\n",
      "[X3:1-2] -> b3 (0.25)\n",
      "[S:0-2] -> [X3:0-1] [X3:1-2] (0.25)\n"
     ]
    }
   ],
   "source": [
    "sentence = synthetic_corpus[1]\n",
    "cky_forest = cky(synthetic, sentence)\n",
    "print cky_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Update $q(\\phi)$ ('M-step')\n",
    "\n",
    "Needed: corpus, inside-outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'big', 'mouse', 'chased', 'a', 'dog']\n"
     ]
    }
   ],
   "source": [
    "# expected_counts = inside_outside(hdp_corpus, hdp_pcfg, start_sym='[S]')\n",
    "from itertools import product\n",
    "\n",
    "grammar = hdp_pcfg\n",
    "corpus = hdp_corpus\n",
    "\n",
    "sentence = hdp_corpus[1]\n",
    "print sentence\n",
    "\n",
    "expected_counts1 = inside_outside([sentence], grammar, start_sym='[S]')\n",
    "\n",
    "expected_counts = inside_outside(corpus, grammar, start_sym='[S]')\n",
    "normalized_counts = {rule: count/float(len(corpus)) for rule,count in expected_counts.iteritems()}\n",
    "\n",
    "# print expected_counts1\n",
    "# print expected_counts\n",
    "# print normalized_counts\n",
    "\n",
    "\n",
    "sigma = grammar.terminals\n",
    "S = grammar.nonterminals\n",
    "S2 = list(product(S,S))\n",
    "T = ['E', 'B']\n",
    "\n",
    "# print sigma\n",
    "# print S\n",
    "# print S2\n",
    "\n",
    "a_E = 0.5\n",
    "a_B = 0.5\n",
    "a_T = 0.5\n",
    "\n",
    "alpha_E = {w: a_E for w in sigma}\n",
    "alpha_B = {N: a_B for N in S2}\n",
    "alpha_T = {t: a_T for t in T}\n",
    "\n",
    "gamma_E = {z: {w: a_E for w in sigma} for z in S}\n",
    "gamma_B = {z: {N: a_B for N in S2} for z in S}\n",
    "gamma_T = {z: {t: a_T for t in T} for z in S}\n",
    "\n",
    "\n",
    "for rule, count in normalized_counts.iteritems():\n",
    "    if len(rule.rhs) > 1:\n",
    "        gamma_B[rule.lhs][rule.rhs] += count\n",
    "        gamma_T[rule.lhs]['B'] += count\n",
    "    else:\n",
    "        gamma_E[rule.lhs][rule.rhs[0]] += count\n",
    "        gamma_T[rule.lhs]['E'] += count\n",
    "\n",
    "# print '\\n'\n",
    "# print gamma_E\n",
    "# print '\\n'\n",
    "# print gamma_B\n",
    "# print '\\n'\n",
    "# print gamma_T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial updates ('E-step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.special import digamma\n",
    "from math import exp\n",
    "# for each nonterminal z a dictionary with keys in sigma\n",
    "W_E = {z: {w: a_E for w in sigma} for z in S}\n",
    "W_B = {z: {N: a_B for N in S2} for z in S}\n",
    "W_T = {z: {t: a_T for t in T} for z in S}\n",
    "\n",
    "for z in S:\n",
    "    E_total = 0.0\n",
    "    for w in sigma:\n",
    "        v = gamma_E[z][w]\n",
    "        W_E[z][w] = exp(digamma(v))\n",
    "        E_total += v\n",
    "    for w in sigma:\n",
    "        W_E[z][w] *= exp(digamma(E_total))\n",
    "    \n",
    "    B_total = 0.0\n",
    "    for N in S2:\n",
    "        v = gamma_B[z][N]\n",
    "        W_B[z][N] = exp(digamma(v))\n",
    "        B_total += v\n",
    "    for N in S2:\n",
    "        W_B[z][N] *= exp(digamma(B_total))\n",
    "    \n",
    "    T_total = 0.0\n",
    "    for t in T:\n",
    "        v = gamma_T[z][t]\n",
    "        W_T[z][t] = exp(digamma(v))\n",
    "        T_total += v\n",
    "    for t in T:\n",
    "        W_T[z][t] *= exp(digamma(T_total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'dog', 'ate', 'the', 'big', 'mouse']\n",
      "[NN:1-2] -> dog (0.34)\n",
      "[DT:0-1] -> the (0.5)\n",
      "[S:0-6] -> [NP:0-2] [VP:2-6] (1.0)\n",
      "[NP:3-6] -> [DT:3-4] [NPBAR:4-6] (0.5)\n",
      "[VB:2-3] -> ate (0.5)\n",
      "[VP:2-6] -> [VB:2-3] [NP:3-6] (1.0)\n",
      "[NN:5-6] -> mouse (0.33)\n",
      "[NPBAR:4-6] -> [JJ:4-5] [NN:5-6] (0.5)\n",
      "[NP:0-2] -> [DT:0-1] [NN:1-2] (0.5)\n",
      "[JJ:4-5] -> big (0.5)\n",
      "[DT:3-4] -> the (0.5)\n",
      "45.013780626\n"
     ]
    }
   ],
   "source": [
    "sentence =  hdp_corpus[6]\n",
    "print sentence\n",
    "\n",
    "def get_base_symbol(symbol):\n",
    "    \"\"\"\n",
    "    Returns the span from a symbol\n",
    "    E.g. input [NN:2-3] returns [NN]\n",
    "    \"\"\"\n",
    "    return symbol.split(':')[0]+']'\n",
    "\n",
    "forest = cky(grammar, sentence)\n",
    "print forest\n",
    "\n",
    "new_grammar = {}\n",
    "for rule in forest:\n",
    "    q_z = 1.0\n",
    "    if len(rule.rhs) > 1:\n",
    "        # we've found a B\n",
    "        z = get_base_symbol(rule.lhs)\n",
    "        c1 = get_base_symbol(rule.rhs[0])\n",
    "        c2 = get_base_symbol(rule.rhs[1])\n",
    "        q_z *= W_B[z][(c1,c2)] * W_T[z]['B']\n",
    "    else:\n",
    "        # we've found an E\n",
    "        z = get_base_symbol(rule.lhs)\n",
    "        w = rule.rhs[0]\n",
    "        q_z *= W_E[z][w] * W_T[z]['E']\n",
    "print q_z\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
