{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Inference\n",
    "\n",
    "In this lab we will discuss some inference problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cfg import WCFG, read_grammar_rules\n",
    "from parser import cky\n",
    "from symbol import make_symbol, is_nonterminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T] -> [P] (0.5)\n",
      "[T] -> [T] * [P] (0.4)\n",
      "[T] -> [T] + [P] (0.1)\n",
      "[E] -> [T] (0.5)\n",
      "[E] -> [E] + [T] (0.45)\n",
      "[E] -> [E] * [T] (0.05)\n",
      "[P] -> a (1.0)\n"
     ]
    }
   ],
   "source": [
    "# let's use our ambiguous grammar this time\n",
    "G = WCFG(read_grammar_rules(open('examples/ambiguous', 'r')))\n",
    "print G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', '+', 'a', '*', 'a']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'a + a * a'.split()\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest = cky(G, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:2-3] -> [T:2-3] (0.5)\n",
      "[E:4-5] -> [T:4-5] (0.5)\n",
      "[T:0-3] -> [T:0-1] + [P:2-3] (0.1)\n",
      "[T:0-5] -> [T:0-3] * [P:4-5] (0.4)\n",
      "[E:0-5] -> [T:0-5] (0.5)\n",
      "[E:0-5] -> [E:0-3] * [T:4-5] (0.05)\n",
      "[E:0-5] -> [E:0-1] + [T:2-5] (0.45)\n",
      "[T:0-1] -> [P:0-1] (0.5)\n",
      "[E:0-1] -> [T:0-1] (0.5)\n",
      "[E:0-3] -> [E:0-1] + [T:2-3] (0.45)\n",
      "[E:0-3] -> [T:0-3] (0.5)\n",
      "[E:2-5] -> [E:2-3] * [T:4-5] (0.05)\n",
      "[E:2-5] -> [T:2-5] (0.5)\n",
      "[P:0-1] -> a (1.0)\n",
      "[T:4-5] -> [P:4-5] (0.5)\n",
      "[P:2-3] -> a (1.0)\n",
      "[T:2-5] -> [T:2-3] * [P:4-5] (0.4)\n",
      "[T:2-3] -> [P:2-3] (0.5)\n",
      "[P:4-5] -> a (1.0)\n"
     ]
    }
   ],
   "source": [
    "print forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: the goal symbol after parsing is the original *start* symbol annotated from *0* to *n* (the length of the sentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[E:0-5]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal = make_symbol('[E]', 0, len(sentence))\n",
    "goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inside weights\n",
    "\n",
    "The inside recursion accumulates the weight of all subtrees under a certain node.\n",
    "\n",
    "        I(v) = \n",
    "            1                           if v is terminal\n",
    "            0                           if v is nonterminal and BS(v) is empty\n",
    "            \\sum_{e \\in BS(v)} w(e) \\prod_{u \\in tail(e)} I(u)   \n",
    "                                        otherwise\n",
    "                                        \n",
    "Here we are going to compute inside weights for acyclic forests, for a more general treatment see Goodman's \"Semiring Parsing\" paper (1999).\n",
    "\n",
    "Inside weights can be used, for instance, to answer the question:\n",
    "\n",
    "* what is the probability of sentence x?\n",
    "\n",
    "It can also be used to find the best derivation and to sample derivations, as we will show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inside(forest, start):  # acyclic hypergraph\n",
    "    \"\"\"\n",
    "    The inside recursion for acyclic hypergraphs.\n",
    "    \n",
    "    :param forest: an acyclic WCFG\n",
    "    :param start: the start symbol (str)\n",
    "    :returns: a dictionary mapping a symbol (terminal or noterminal) to its inside weight\n",
    "    \"\"\"\n",
    "    I = dict()\n",
    "    \n",
    "    def get_inside(symbol):\n",
    "        \"\"\"computes inside recursively\"\"\"\n",
    "        w = I.get(symbol, None)\n",
    "        if w is not None:  # already computed\n",
    "            return w\n",
    "        incoming = forest.get(symbol, set())\n",
    "        if len(incoming) == 0:  # terminals have already been handled, this must be a nonterminal dead end\n",
    "            # store it to avoid repeating computation in the future\n",
    "            I[symbol] = 0.0  \n",
    "            return 0.0\n",
    "        # accumulate the inside contribution of each incoming edge\n",
    "        w = 0.0\n",
    "        for rule in incoming:\n",
    "            k = rule.prob\n",
    "            for child in rule.rhs:\n",
    "                k *= get_inside(child)\n",
    "            w += k\n",
    "        # store it to avoid repeating computation in the future\n",
    "        I[symbol] = w\n",
    "        return w\n",
    "    \n",
    "    # handles terminals\n",
    "    for sym in forest.terminals:\n",
    "        I[sym] = 1.0\n",
    "    # recursively solves the inside formula from the start symbol\n",
    "    get_inside(start)\n",
    "        \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I = inside(forest, goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inside at the root represents the probability of the sentence\n",
    "\n",
    "    p(x) = \\sum_d p(x, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034531250000000006"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I[goal]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Counting derivations\n",
    "\n",
    "Another interesting question is\n",
    "\n",
    "* how many analyses of a given sentence do we have?\n",
    "\n",
    "This question is very simple to answer for acyclic hypergraphs and it turns out to be a special case of the inside recursion.\n",
    "\n",
    "        N(v) = \n",
    "            1                           if v is terminal\n",
    "            0                           if v is nonterminal and BS(v) is empty\n",
    "            \\sum_{e \\in BS(v)} 1 * \\prod_{u \\in tail(e)} N(u)   \n",
    "                                        otherwise\n",
    "                                        \n",
    "Compare the definition above with the inside recursion presented earlier.\n",
    "Also compare the program below with the inside computation and comment on the differences.\n",
    "\n",
    "Can you explain this recursion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counting(forest, start):  # acyclic hypergraph\n",
    "    N = dict()\n",
    "    \n",
    "    def get_count(symbol):\n",
    "        w = N.get(symbol, None)\n",
    "        if w is not None:\n",
    "            return w\n",
    "        incoming = forest.get(symbol, set())\n",
    "        if len(incoming) == 0:  # terminals have already been handled, this must be a nonterminal dead end\n",
    "            N[symbol] = w\n",
    "            return 0\n",
    "        w = 0\n",
    "        for rule in incoming:\n",
    "            k = 1\n",
    "            for child in rule.rhs:\n",
    "                k *= get_count(child)\n",
    "            w += k\n",
    "        N[symbol] = w\n",
    "        return w\n",
    "    \n",
    "    # handles terminals\n",
    "    for sym in forest.terminals:\n",
    "        N[sym] = 1\n",
    "    # handles nonterminals\n",
    "    #for sym in forest.nonterminals:\n",
    "    #    get_inside(sym)\n",
    "    get_count(start)\n",
    "        \n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = counting(forest, goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of derivations is associated with the value of N at the root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[goal]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi (best derivation)\n",
    "\n",
    "We might want to know which analysis score highest. That is,\n",
    "\n",
    "        d* = argmax_d p(x, d)\n",
    "        \n",
    "where d ranges over all possible derivations.\n",
    "\n",
    "Once we have computed inside weights, this is extremely simple to solve.\n",
    "However, we can also define a recursion which is specific for the computation of the Viterbi derivation. Do you think you can come up with its formula? Can you implement it?\n",
    "        \n",
    "        \n",
    "Below, an implementation based on inside weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "def viterbi(forest, I, start):\n",
    "    Q = deque([start])\n",
    "    d = []\n",
    "    while Q:\n",
    "        parent = Q.popleft()\n",
    "        incoming = forest.get(parent)\n",
    "        # here we will find the distribution over edges\n",
    "        weights = [0.0] * len(incoming)\n",
    "        for i, rule in enumerate(incoming):\n",
    "            weights[i] = rule.prob\n",
    "            for child in rule.rhs:\n",
    "                weights[i] *= I[child]\n",
    "        # here we select the edge that is the maximum of this distribution\n",
    "        weight, selected = max(zip(weights, incoming))\n",
    "        # we also need to queue the nonterminals in the tail of the edge\n",
    "        for sym in selected.rhs:\n",
    "            if is_nonterminal(sym):\n",
    "                Q.append(sym)\n",
    "        # and finally, add the selected edge to the derivation\n",
    "        d.append(selected)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[E:0-5] -> [E:0-1] + [T:2-5] (0.45),\n",
       " [E:0-1] -> [T:0-1] (0.5),\n",
       " [T:2-5] -> [T:2-3] * [P:4-5] (0.4),\n",
       " [T:0-1] -> [P:0-1] (0.5),\n",
       " [T:2-3] -> [P:2-3] (0.5),\n",
       " [P:4-5] -> a (1.0),\n",
       " [P:0-1] -> a (1.0),\n",
       " [P:2-3] -> a (1.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = viterbi(forest, I, goal)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joint probability p(d, x) of the derivation is given by the product over its rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def joint_probability(d):\n",
    "    prob = 1.0\n",
    "    for r in d:\n",
    "        prob *= r.prob\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022500000000000003"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_probability(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional probability p(d|x) is given by\n",
    "\n",
    "    p(d|x) = p(d,x)/p(x)\n",
    "\n",
    "and we know that \n",
    "\n",
    "    p(x) = \\sum_d p(d,x)\n",
    "    \n",
    "is given by the inside at the root.\n",
    "\n",
    "Thus, the following is the conditional probability of the best derivation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6515837104072397"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_probability(d)/I[goal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can use this utilitary method to draw trees\n",
    "from util import make_nltk_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(E:0-5\n",
      "  (E:0-1 (T:0-1 (P:0-1 a)))\n",
      "  +\n",
      "  (T:2-5 (T:2-3 (P:2-3 a)) * (P:4-5 a)))\n"
     ]
    }
   ],
   "source": [
    "t = make_nltk_tree(d)\n",
    "print t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*the following will open a pop-up window and you need to find it ;)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "\n",
    "Often we are interested in drawing random samples from the distribution p(d|x).\n",
    "\n",
    "We can do that by sampling from the inverted CDF associated with p(d|x).\n",
    "The conditional independence assumption central to PCFGs make them convenient for sampling by *ancestral sampling*.\n",
    "\n",
    "The code below is very similar to the Viterbi code above, however, instead of maximising at each step, we draw a random edge from the distribution defined by their inside weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "def sample(forest, I, start):\n",
    "    Q = deque([start])\n",
    "    d = []\n",
    "    while Q:\n",
    "        parent = Q.popleft()\n",
    "        incoming = forest.get(parent)\n",
    "        # here we compute the distribution over edges\n",
    "        weights = [0.0] * len(incoming)\n",
    "        for i, rule in enumerate(incoming):\n",
    "            weights[i] = rule.prob\n",
    "            for child in rule.rhs:\n",
    "                weights[i] *= I[child]\n",
    "        # here we draw a random threshold (think of it as sampling from the inverted CDF)\n",
    "        th = random.uniform(0, I[parent])\n",
    "        # here we compute the CDF step by step and check\n",
    "        # for which edge e whether cdf(e) > th\n",
    "        total = 0.0\n",
    "        selected = None\n",
    "        back = None\n",
    "        for w, rule in zip(weights, incoming):\n",
    "            total += w\n",
    "            if total > th:\n",
    "                selected = rule\n",
    "                break\n",
    "            else:\n",
    "                back = rule\n",
    "        if selected is None:  # this is to deal with corner cases due to rounding problems\n",
    "            selected = back\n",
    "        # every nonterminal child of the selected edge must be added to the queue\n",
    "        for sym in selected.rhs:\n",
    "            if is_nonterminal(sym):\n",
    "                Q.append(sym)\n",
    "        d.append(selected)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we draw a random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[E:0-5] -> [T:0-5] (0.5),\n",
       " [T:0-5] -> [T:0-3] * [P:4-5] (0.4),\n",
       " [T:0-3] -> [T:0-1] + [P:2-3] (0.1),\n",
       " [P:4-5] -> a (1.0),\n",
       " [T:0-1] -> [P:0-1] (0.5),\n",
       " [P:2-3] -> a (1.0),\n",
       " [P:0-1] -> a (1.0)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(forest, I, goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical distribution\n",
    "\n",
    "A nice thing to do whe we can sample is to obtain an empirical distribution.\n",
    "That is, we draw a number of independent samples from the underlying distribution and approximate their probabilities by their relative frequency in the sample. The law of large numbers says that our estimates converge to true probabilities as we sample more. That also holds for expectations that we might want to compute based on the underlying distribution.\n",
    "\n",
    "Note how our estimates are pretty close to the true probabilities. This is because we are drawing indepent samples from the exact conditional distribution p(d|x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# n=661 prob=0.651583710407 estimate=0.661\n",
      "(E:0-5\n",
      "  (E:0-1 (T:0-1 (P:0-1 a)))\n",
      "  +\n",
      "  (T:2-5 (T:2-3 (P:2-3 a)) * (P:4-5 a)))\n",
      "\n",
      "# n=297 prob=0.289592760181 estimate=0.297\n",
      "(E:0-5 (T:0-5 (T:0-3 (T:0-1 (P:0-1 a)) + (P:2-3 a)) * (P:4-5 a)))\n",
      "\n",
      "# n=30 prob=0.0407239819005 estimate=0.03\n",
      "(E:0-5\n",
      "  (E:0-3 (E:0-1 (T:0-1 (P:0-1 a))) + (T:2-3 (P:2-3 a)))\n",
      "  *\n",
      "  (T:4-5 (P:4-5 a)))\n",
      "\n",
      "# n=12 prob=0.0180995475113 estimate=0.012\n",
      "(E:0-5\n",
      "  (E:0-3 (T:0-3 (T:0-1 (P:0-1 a)) + (P:2-3 a)))\n",
      "  *\n",
      "  (T:4-5 (P:4-5 a)))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# an example of how to estimate an empirical distribution out of 100 samples\n",
    "from collections import defaultdict\n",
    "counts = defaultdict(int)\n",
    "n_samples = 1000\n",
    "# here we sample a number of derivations\n",
    "for i in range(n_samples):\n",
    "    d = tuple(sample(forest, I, goal))\n",
    "    counts[d] += 1  # counting how often we they get sampled\n",
    "\n",
    "# here we sort them by frequency from most frequent to least frequent\n",
    "for d, n in sorted(counts.iteritems(), key=lambda (d, n): n, reverse=True):\n",
    "    # here we compute the exact probability (for comparison)\n",
    "    prob = joint_probability(d)/I[goal]\n",
    "    # here we compute an empirical estimate\n",
    "    estimate = float(n)/n_samples\n",
    "    t = make_nltk_tree(d)\n",
    "    print '# n=%d prob=%s estimate=%s\\n%s' % (n, prob, estimate, str(t))\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that our grammar, even though ambiguous, expresses a strong preference (a little over 65%) for the analysis that solves the product before the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
