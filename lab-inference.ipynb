{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Inference\n",
    "\n",
    "In this lab we will discuss some inference problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rule import Rule\n",
    "from cfg import WCFG, read_grammar_rules\n",
    "from parser import cky\n",
    "from earley import earley\n",
    "from symbol import make_symbol, is_nonterminal, is_terminal\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T] -> [P] (0.5)\n",
      "[T] -> [T] * [P] (0.4)\n",
      "[T] -> [T] + [P] (0.1)\n",
      "[E] -> [T] (0.5)\n",
      "[E] -> [E] + [T] (0.45)\n",
      "[E] -> [E] * [T] (0.05)\n",
      "[P] -> a (1.0)\n"
     ]
    }
   ],
   "source": [
    "# let's use our ambiguous grammar this time\n",
    "G = WCFG(read_grammar_rules(open('examples/ambiguous', 'r')))\n",
    "print G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', '+', 'a', '*', 'a']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'a + a * a'.split()\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest = cky(G, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:2-3] -> [T:2-3] (0.5)\n",
      "[E:4-5] -> [T:4-5] (0.5)\n",
      "[T:0-3] -> [T:0-1] + [P:2-3] (0.1)\n",
      "[T:0-5] -> [T:0-3] * [P:4-5] (0.4)\n",
      "[E:0-5] -> [T:0-5] (0.5)\n",
      "[E:0-5] -> [E:0-3] * [T:4-5] (0.05)\n",
      "[E:0-5] -> [E:0-1] + [T:2-5] (0.45)\n",
      "[T:0-1] -> [P:0-1] (0.5)\n",
      "[E:0-1] -> [T:0-1] (0.5)\n",
      "[E:0-3] -> [E:0-1] + [T:2-3] (0.45)\n",
      "[E:0-3] -> [T:0-3] (0.5)\n",
      "[E:2-5] -> [E:2-3] * [T:4-5] (0.05)\n",
      "[E:2-5] -> [T:2-5] (0.5)\n",
      "[P:0-1] -> a (1.0)\n",
      "[T:4-5] -> [P:4-5] (0.5)\n",
      "[P:2-3] -> a (1.0)\n",
      "[T:2-5] -> [T:2-3] * [P:4-5] (0.4)\n",
      "[T:2-3] -> [P:2-3] (0.5)\n",
      "[P:4-5] -> a (1.0)\n"
     ]
    }
   ],
   "source": [
    "print forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: the goal symbol after parsing is the original *start* symbol annotated from *0* to *n* (the length of the sentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[E:0-5]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal = make_symbol('[E]', 0, len(sentence))\n",
    "goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use earley to parse the sentence. For this we also need to pass the parser the start symbol that we are using, as earley uses this to produce its axioms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T:0-3] -> [T:0-1] + [P:2-3] (0.1)\n",
      "[T:0-5] -> [T:0-3] * [P:4-5] (0.4)\n",
      "[E:0-5] -> [T:0-5] (0.5)\n",
      "[E:0-5] -> [E:0-3] * [T:4-5] (0.05)\n",
      "[E:0-5] -> [E:0-1] + [T:2-5] (0.45)\n",
      "[T:0-1] -> [P:0-1] (0.5)\n",
      "[E:0-1] -> [T:0-1] (0.5)\n",
      "[E:0-3] -> [E:0-1] + [T:2-3] (0.45)\n",
      "[E:0-3] -> [T:0-3] (0.5)\n",
      "[P:0-1] -> a (1.0)\n",
      "[T:4-5] -> [P:4-5] (0.5)\n",
      "[P:2-3] -> a (1.0)\n",
      "[T:2-5] -> [T:2-3] * [P:4-5] (0.4)\n",
      "[T:2-3] -> [P:2-3] (0.5)\n",
      "[P:4-5] -> a (1.0)\n"
     ]
    }
   ],
   "source": [
    "earley_forest = earley(G, sentence, start='[E]')\n",
    "print earley_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the forest generated by Earley are smaller than the forest generated by CKY: Earley has a built-in top-down filter that removes redundant elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print len(forest)\n",
    "print len(earley_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a corpus\n",
    "\n",
    "We can use a grammar generate a corpus using ancestral sampling. Here we use the ambiguous grammar given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', '*', 'a', '*', 'a', '*', 'a', '*', 'a', '+', 'a'], ['a', '*', 'a', '*', 'a', '*', 'a'], ['a'], ['a', '*', 'a', '*', 'a', '*', 'a', '*', 'a'], ['a', '*', 'a', '+', 'a', '*', 'a', '+', 'a'], ['a'], ['a', '*', 'a', '+', 'a', '*', 'a', '*', 'a', '*', 'a', '*', 'a', '*', 'a'], ['a', '*', 'a', '+', 'a'], ['a', '+', 'a'], ['a', '*', 'a'], ['a', '*', 'a', '*', 'a', '*', 'a'], ['a', '*', 'a', '+', 'a', '*', 'a', '+', 'a'], ['a', '+', 'a', '+', 'a', '*', 'a', '*', 'a', '*', 'a'], ['a'], ['a'], ['a', '*', 'a'], ['a', '+', 'a'], ['a', '*', 'a', '+', 'a', '*', 'a', '*', 'a', '*', 'a', '+', 'a'], ['a', '+', 'a'], ['a', '+', 'a', '*', 'a', '+', 'a', '+', 'a', '+', 'a', '+', 'a', '*', 'a'], ['a'], ['a', '+', 'a', '+', 'a'], ['a', '*', 'a'], ['a', '*', 'a', '*', 'a', '*', 'a'], ['a'], ['a', '+', 'a'], ['a', '+', 'a', '+', 'a', '+', 'a', '*', 'a'], ['a', '+', 'a'], ['a', '+', 'a', '+', 'a', '*', 'a', '+', 'a', '+', 'a', '*', 'a', '*', 'a'], ['a', '+', 'a', '+', 'a'], ['a', '*', 'a', '*', 'a', '+', 'a', '*', 'a'], ['a', '+', 'a', '*', 'a', '+', 'a'], ['a'], ['a', '+', 'a', '*', 'a'], ['a', '*', 'a', '*', 'a', '+', 'a', '+', 'a', '*', 'a', '+', 'a', '+', 'a'], ['a'], ['a', '*', 'a', '*', 'a', '+', 'a'], ['a'], ['a', '*', 'a'], ['a', '+', 'a', '+', 'a', '*', 'a'], ['a', '*', 'a'], ['a'], ['a', '*', 'a', '*', 'a', '*', 'a', '+', 'a', '*', 'a', '*', 'a', '*', 'a', '+', 'a'], ['a', '*', 'a', '*', 'a'], ['a', '+', 'a', '*', 'a', '*', 'a', '+', 'a', '+', 'a'], ['a', '+', 'a', '*', 'a'], ['a', '+', 'a'], ['a', '+', 'a', '*', 'a'], ['a', '+', 'a', '+', 'a', '+', 'a'], ['a', '+', 'a', '+', 'a'], ['a', '*', 'a', '+', 'a', '*', 'a', '+', 'a', '*', 'a', '*', 'a', '+', 'a'], ['a'], ['a', '+', 'a', '*', 'a'], ['a'], ['a', '+', 'a', '*', 'a', '*', 'a', '+', 'a'], ['a'], ['a', '*', 'a', '+', 'a', '+', 'a', '+', 'a', '*', 'a', '*', 'a', '+', 'a'], ['a', '+', 'a', '*', 'a', '*', 'a'], ['a', '+', 'a', '*', 'a', '+', 'a'], ['a'], ['a'], ['a'], ['a', '*', 'a', '+', 'a', '*', 'a', '*', 'a'], ['a', '*', 'a', '*', 'a', '+', 'a', '*', 'a', '*', 'a'], ['a', '+', 'a', '+', 'a', '*', 'a', '+', 'a', '+', 'a'], ['a'], ['a'], ['a', '*', 'a', '+', 'a'], ['a'], ['a'], ['a', '*', 'a', '+', 'a'], ['a', '+', 'a', '*', 'a', '*', 'a'], ['a'], ['a', '+', 'a', '*', 'a', '*', 'a', '+', 'a', '+', 'a', '+', 'a', '+', 'a'], ['a'], ['a', '+', 'a', '*', 'a', '*', 'a'], ['a', '*', 'a', '*', 'a', '+', 'a', '*', 'a', '*', 'a', '*', 'a', '*', 'a'], ['a', '*', 'a', '*', 'a', '+', 'a', '*', 'a'], ['a', '+', 'a', '+', 'a', '+', 'a', '+', 'a', '*', 'a', '*', 'a', '+', 'a', '*', 'a', '+', 'a'], ['a', '*', 'a', '+', 'a', '+', 'a', '*', 'a'], ['a', '+', 'a', '+', 'a', '*', 'a', '*', 'a', '+', 'a', '*', 'a', '*', 'a', '*', 'a', '+', 'a', '+', 'a'], ['a', '*', 'a'], ['a', '*', 'a'], ['a'], ['a', '*', 'a', '*', 'a', '*', 'a', '+', 'a', '+', 'a', '*', 'a', '+', 'a', '*', 'a', '*', 'a', '+', 'a', '+', 'a', '+', 'a', '*', 'a', '*', 'a', '*', 'a'], ['a', '+', 'a', '*', 'a', '+', 'a', '+', 'a', '+', 'a', '+', 'a', '*', 'a', '+', 'a', '+', 'a'], ['a', '+', 'a', '*', 'a', '+', 'a'], ['a'], ['a'], ['a', '*', 'a', '*', 'a'], ['a', '*', 'a', '*', 'a', '*', 'a'], ['a', '*', 'a', '+', 'a', '*', 'a', '*', 'a', '*', 'a', '*', 'a', '*', 'a'], ['a'], ['a', '+', 'a', '*', 'a', '+', 'a', '*', 'a', '+', 'a', '*', 'a', '+', 'a', '*', 'a'], ['a', '+', 'a', '+', 'a', '+', 'a'], ['a', '+', 'a', '*', 'a', '+', 'a', '+', 'a', '+', 'a', '+', 'a', '*', 'a'], ['a', '*', 'a', '+', 'a', '*', 'a'], ['a', '*', 'a', '+', 'a', '+', 'a', '*', 'a', '+', 'a', '+', 'a', '+', 'a', '+', 'a'], ['a', '*', 'a', '*', 'a', '+', 'a'], ['a', '+', 'a', '+', 'a', '+', 'a', '*', 'a']]\n"
     ]
    }
   ],
   "source": [
    "def generate_sample(grammar, items=('[E]',)):\n",
    "    \"\"\"\n",
    "    Given a grammar returns a sentence from it using\n",
    "    the probabilities specfied in the grammar.\n",
    "    :param items: call the function with (start,) where \n",
    "                  start is the start symbol of the grammar\n",
    "    :returns: a sentence from the language as a list\n",
    "    \"\"\"\n",
    "    frags = []\n",
    "    for item in items:\n",
    "        if is_nonterminal(item):\n",
    "            productions = grammar.get(item)\n",
    "            ps = [production.prob for production in productions]\n",
    "            random_index = np.argmax(np.random.multinomial(1, ps, size=1))\n",
    "            prod = productions[random_index]\n",
    "            frags.extend(generate_sample(grammar, items=prod.rhs))\n",
    "        else:\n",
    "            frags.append(item)\n",
    "    return frags\n",
    "\n",
    "# print generate_sample(G)\n",
    "\n",
    "def generate_corpus(grammar, n, start=('[E]',),):\n",
    "    \"\"\"\n",
    "    Generates a corpus using the grammar\n",
    "    :param n: size of the corpus\n",
    "    :params: same a s generate corpus\n",
    "    :returns: a corpus in the form of a list\n",
    "    \"\"\"\n",
    "    return [generate_sample(grammar, items=start) for i in range(n)]\n",
    "\n",
    "corpus1 = generate_corpus(G, 100)\n",
    "corpus2 = generate_corpus(G, 1000)\n",
    "corpus3 = generate_corpus(G, 10000)\n",
    "\n",
    "print corpus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T:2-7] -> [T:2-5] * [P:6-7] (0.4)\n",
      "[E:0-3] -> [E:0-1] * [T:2-3] (0.05)\n",
      "[E:0-3] -> [T:0-3] (0.5)\n",
      "[P:0-1] -> a (1.0)\n",
      "[E:0-7] -> [E:0-1] * [T:2-7] (0.05)\n",
      "[E:0-7] -> [E:0-3] * [T:4-7] (0.05)\n",
      "[E:0-7] -> [E:0-5] * [T:6-7] (0.05)\n",
      "[E:0-7] -> [T:0-7] (0.5)\n",
      "[T:0-3] -> [T:0-1] * [P:2-3] (0.4)\n",
      "[T:0-5] -> [T:0-3] * [P:4-5] (0.4)\n",
      "[T:0-1] -> [P:0-1] (0.5)\n",
      "[T:2-5] -> [T:2-3] * [P:4-5] (0.4)\n",
      "[T:2-3] -> [P:2-3] (0.5)\n",
      "[T:4-7] -> [T:4-5] * [P:6-7] (0.4)\n",
      "[T:6-7] -> [P:6-7] (0.5)\n",
      "[E:6-7] -> [T:6-7] (0.5)\n",
      "[T:4-5] -> [P:4-5] (0.5)\n",
      "[P:6-7] -> a (1.0)\n",
      "[P:2-3] -> a (1.0)\n",
      "[T:0-7] -> [T:0-5] * [P:6-7] (0.4)\n",
      "[E:4-5] -> [T:4-5] (0.5)\n",
      "[E:4-7] -> [T:4-7] (0.5)\n",
      "[E:4-7] -> [E:4-5] * [T:6-7] (0.05)\n",
      "[E:2-3] -> [T:2-3] (0.5)\n",
      "[E:0-5] -> [T:0-5] (0.5)\n",
      "[E:0-5] -> [E:0-3] * [T:4-5] (0.05)\n",
      "[E:0-5] -> [E:0-1] * [T:2-5] (0.05)\n",
      "[E:0-1] -> [T:0-1] (0.5)\n",
      "[E:2-5] -> [E:2-3] * [T:4-5] (0.05)\n",
      "[E:2-5] -> [T:2-5] (0.5)\n",
      "[P:4-5] -> a (1.0)\n",
      "[E:2-7] -> [E:2-3] * [T:4-7] (0.05)\n",
      "[E:2-7] -> [T:2-7] (0.5)\n",
      "[E:2-7] -> [E:2-5] * [T:6-7] (0.05)\n"
     ]
    }
   ],
   "source": [
    "sentence2 = corpus1[1]\n",
    "\n",
    "forest2 = cky(G, sentence2)\n",
    "print forest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inside' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-31c7987f4b1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgoal2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_symbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[E]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mI2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minside\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mI2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inside' is not defined"
     ]
    }
   ],
   "source": [
    "goal2 = make_symbol('[E]', 0, len(sentence2))\n",
    "\n",
    "I2 = inside(forest2, goal2)\n",
    "\n",
    "print I2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An alternative grammar\n",
    "\n",
    "Here we generate a corpus from a grammar taken from the NLTK toolkit. We use a Dirichlet distribution to give the productions random probabilities. Larger alpha gives more uniform distributions; smaller alpha gives more biased distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initialize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ac9a69a96914>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# We give the grammar some random probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# that are not too uniform and moderately biased:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtoy_grammar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoy_grammar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtoy_grammar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initialize' is not defined"
     ]
    }
   ],
   "source": [
    "toy_grammar = WCFG(read_grammar_rules(open('examples/nltk-grammar', 'r')))\n",
    "# print toy_grammar\n",
    "\n",
    "# We give the grammar some random probabilities \n",
    "# that are not too uniform and moderately biased:\n",
    "toy_grammar = initialize(toy_grammar, alpha=0.5)\n",
    "print toy_grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this grammar we can also generate a corpus. Note that the sentences can have an enormous number of different parses. The grammar can quite easliy generate very long sentences, and is very ambiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Jack', 'ate'], ['Jack', 'with', 'Jack', 'with', 'Jack', 'with', 'Jack', 'saw'], ['Jack', 'ate'], ['Jack', 'saw'], ['Jack', 'ate'], ['Jack', 'saw'], ['the', 'hill', 'under', 'Jack', 'ate'], ['Jack', 'saw'], ['Jack', 'saw', 'Bob'], ['Jack', 'saw', 'Jack']]\n",
      "[1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 429, 1, 1, 1, 117572, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 2, 2, 1, 1, 1, 1, 14, 1, 1, 1, 1, 10, 1, 1, 1, 1, 1, 1, 132, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 5, 1, 742900, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 5, 2, 1, 2, 14, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "generate_sample(toy_grammar, items=('[S]',))\n",
    "toy_corpus = generate_corpus(toy_grammar, 100, start=('[S]',))\n",
    "print toy_corpus[0:10]\n",
    "\n",
    "def checking_number_parses(n=100):\n",
    "    number = list()\n",
    "    for sentence in toy_corpus[0:n]:\n",
    "        toy_forest = cky(toy_grammar, sentence)\n",
    "        toy_goal = make_symbol('[S]', 0, len(sentence))\n",
    "        N_toy = counting(toy_forest, toy_goal)\n",
    "        number.append(N_toy[toy_goal])\n",
    "    return number\n",
    "\n",
    "print checking_number_parses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing the parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[E:0-15] -> [E:0-13] + [T:14-15] (0.45), [E:0-13] -> [E:0-11] + [T:12-13] (0.45), [T:14-15] -> [P:14-15] (0.5), [E:0-11] -> [E:0-7] + [T:8-11] (0.45), [T:12-13] -> [P:12-13] (0.5), [P:14-15] -> a (1.0), [E:0-7] -> [E:0-1] + [T:2-7] (0.45), [T:8-11] -> [T:8-9] * [P:10-11] (0.4), [P:12-13] -> a (1.0), [E:0-1] -> [T:0-1] (0.5), [T:2-7] -> [T:2-5] * [P:6-7] (0.4), [T:8-9] -> [P:8-9] (0.5), [P:10-11] -> a (1.0), [T:0-1] -> [P:0-1] (0.5), [T:2-5] -> [T:2-3] * [P:4-5] (0.4), [P:6-7] -> a (1.0), [P:8-9] -> a (1.0), [P:0-1] -> a (1.0), [T:2-3] -> [P:2-3] (0.5), [P:4-5] -> a (1.0), [P:2-3] -> a (1.0)]\n",
      "(E:0-15\n",
      "  (E:0-13\n",
      "    (E:0-11\n",
      "      (E:0-7\n",
      "        (E:0-1 (T:0-1 (P:0-1 a)))\n",
      "        +\n",
      "        (T:2-7 (T:2-5 (T:2-3 (P:2-3 a)) * (P:4-5 a)) * (P:6-7 a)))\n",
      "      +\n",
      "      (T:8-11 (T:8-9 (P:8-9 a)) * (P:10-11 a)))\n",
      "    +\n",
      "    (T:12-13 (P:12-13 a)))\n",
      "  +\n",
      "  (T:14-15 (P:14-15 a)))\n"
     ]
    }
   ],
   "source": [
    "d2 = viterbi(forest2, I2, goal2)\n",
    "\n",
    "print d2\n",
    "t2 = make_nltk_tree(d2)\n",
    "print t2\n",
    "t2.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "N2 = counting(forest2, goal2)\n",
    "print N2[goal2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inside weights\n",
    "\n",
    "The inside recursion accumulates the weight of all subtrees under a certain node.\n",
    "\n",
    "        I(v) = \n",
    "            1                           if v is terminal\n",
    "            0                           if v is nonterminal and BS(v) is empty\n",
    "            \n",
    "$$\\sum_{e \\in BS(v)} w(e) \\prod_{u \\in tail(e)} I(u)$$\n",
    "                                        otherwise\n",
    "                                        \n",
    "Here we are going to compute inside weights for acyclic forests, for a more general treatment see Goodman's \"Semiring Parsing\" paper (1999).\n",
    "\n",
    "Inside weights can be used, for instance, to answer the question:\n",
    "\n",
    "* what is the probability of sentence x?\n",
    "\n",
    "It can also be used to find the best derivation and to sample derivations, as we will show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inside(forest, start):  # acyclic hypergraph\n",
    "    \"\"\"\n",
    "    The inside recursion for acyclic hypergraphs.\n",
    "    \n",
    "    :param forest: an acyclic WCFG\n",
    "    :param start: the start symbol (str)\n",
    "    :returns: a dictionary mapping a symbol (terminal or noterminal) to its inside weight\n",
    "    \"\"\"\n",
    "    I = dict()\n",
    "    \n",
    "    def get_inside(symbol):\n",
    "        \"\"\"computes inside recursively\"\"\"\n",
    "        w = I.get(symbol, None)\n",
    "        if w is not None:  # already computed\n",
    "            return w\n",
    "        incoming = forest.get(symbol, set())\n",
    "        if len(incoming) == 0:  # terminals have already been handled, this must be a nonterminal dead end\n",
    "            # store it to avoid repeating computation in the future\n",
    "            I[symbol] = 0.0\n",
    "            return 0.0\n",
    "        # accumulate the inside contribution of each incoming edge\n",
    "        w = 0.0\n",
    "        for rule in incoming:\n",
    "            k = rule.prob\n",
    "            for child in rule.rhs:\n",
    "                k *= get_inside(child)\n",
    "            w += k\n",
    "        # store it to avoid repeating computation in the future\n",
    "        I[symbol] = w\n",
    "        return w\n",
    "    \n",
    "    # handles terminals\n",
    "    for sym in forest.terminals:\n",
    "        I[sym] = 1.0\n",
    "    # recursively solves the inside formula from the start symbol\n",
    "    get_inside(start)\n",
    "        \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1.0, '[T:0-3]': 0.05, '[T:0-5]': 0.020000000000000004, '[E:0-5]': 0.034531250000000006, '[T:0-1]': 0.5, '+': 1.0, '*': 1.0, '[E:0-3]': 0.08125, '[T:2-3]': 0.5, '[P:0-1]': 1.0, '[T:4-5]': 0.5, '[P:2-3]': 1.0, '[T:2-5]': 0.2, '[E:0-1]': 0.25, '[P:4-5]': 1.0}\n"
     ]
    }
   ],
   "source": [
    "I = inside(forest, goal)\n",
    "\n",
    "print I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inside at the root represents the probability of the sentence:\n",
    "\n",
    "$$p(x) = \\sum_d p(x, d)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outside\n",
    "\n",
    "Computing outside probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[T:2-7] -> [T:2-5] * [P:6-7] (0.4), [E:0-5] -> [E:0-1] * [T:2-5] (0.05), [E:2-5] -> [T:2-5] (0.5)]\n"
     ]
    }
   ],
   "source": [
    "def get_rules_by_rhs(grammar, symbol):\n",
    "    rules = []\n",
    "    for rule in grammar:\n",
    "#         print rule\n",
    "        if symbol in rule.rhs:\n",
    "            rules.append(rule)\n",
    "    return rules\n",
    "\n",
    "print get_rules_by_rhs(forest2, '[T:2-5]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outside(forest, start, inside_dict):\n",
    "    \n",
    "    I = dict()\n",
    "    \n",
    "    def get_outside(symbol):\n",
    "        w = I.get(symbol, None)\n",
    "        if w is not None:  # already computed\n",
    "            return w\n",
    "        outgoing = get_rules_by_rhs(forest, symbol)\n",
    "        beta = 0.0\n",
    "        for rule in outgoing:\n",
    "            k = rule.prob\n",
    "            for child in rule.rhs:\n",
    "                if child != symbol:\n",
    "                    try:\n",
    "                        alpha = inside_dict[child]\n",
    "                    except KeyError:\n",
    "                        # Not sure about this solution...\n",
    "                        # If child is not in inside_dict then child was not seen in the top-down process\n",
    "                        # of the inside algorithm, and hence there is no way to complete child into a \n",
    "                        # parse for the whole sentence. So beta should be 0.0\n",
    "#                         print \"key-error with {}\".format(child)\n",
    "                        alpha = 0.0\n",
    "                    k *= alpha\n",
    "            k *= get_outside(rule.lhs)\n",
    "            beta += k\n",
    "        I[symbol] = beta\n",
    "        return beta\n",
    "    \n",
    "    I[start] = 1.0\n",
    "    \n",
    "    for sym in forest.terminals:\n",
    "#         print \"terminal: {}\".format(sym)\n",
    "        I[sym] = get_outside(sym)\n",
    "    \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0.10359375000000001, '[E:2-3]': 0.0, '[E:4-5]': 0.0, '[T:0-3]': 0.21250000000000002, '[T:0-5]': 0.5, '[E:0-5]': 1.0, '[T:0-1]': 0.06906250000000001, '[E:0-1]': 0.09562500000000002, '*': 0.03453125, '[E:0-3]': 0.025, '[T:4-5]': 0.0040625, '[P:0-1]': 0.034531250000000006, '[P:2-3]': 0.034531250000000006, '[E:2-5]': 0.0, '[T:2-5]': 0.1125, '+': 0.034531250000000006, '[T:2-3]': 0.04781250000000001, '[P:4-5]': 0.03453125}\n"
     ]
    }
   ],
   "source": [
    "print outside(forest, goal, I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inside-Outside\n",
    "\n",
    "We use the inside-outside algorithm to learn probabilities of the rules from unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def initialize(grammar, alpha=20.0):\n",
    "    \"\"\"\n",
    "    Takes a grammar and returns that same grammar but\n",
    "    with the probabilities replaced by random probabilities\n",
    "    generated from a Dirichlet distribution.\n",
    "    :param: alpha is the Dirichlet concentration parameter\n",
    "    \"\"\"\n",
    "    init_grammar = WCFG()\n",
    "    for nonterminal in grammar.nonterminals:\n",
    "        rules = grammar.get(nonterminal)\n",
    "        init_prob = np.random.dirichlet(len(rules)*[alpha])\n",
    "        for i, rule in enumerate(rules):\n",
    "            init_grammar.add(Rule(rule.lhs, rule.rhs, init_prob[i]))\n",
    "    return init_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def get_instances(rule, forest):\n",
    "    \"\"\"\n",
    "    Given a rule\n",
    "    \n",
    "    A -> B C \n",
    "    \n",
    "    get_instances collects all instances of rules of the form\n",
    "    \n",
    "    [A:i-j] -> [B:i-k] [C:k-j] \n",
    "    \n",
    "    from the forest and returns them in a list.\n",
    "    \"\"\"\n",
    "    instances = []\n",
    "    for r in forest:\n",
    "        if r.lhs[1] == rule.lhs[1] and len(r.rhs)==len(rule.rhs):\n",
    "            test = []\n",
    "            for i in range(len(r.rhs)):\n",
    "                try:\n",
    "                    # if for example r.rhs[i] = '[A]' \n",
    "                    v = r.rhs[i][1] == rule.rhs[i][1]\n",
    "                    test.append(v)\n",
    "                except IndexError:\n",
    "                    # if for example r.rhs[i] = '*' \n",
    "                    v = r.rhs[i][0] == rule.rhs[i][0]\n",
    "                    test.append(v)\n",
    "            if np.all(test):\n",
    "                instances.append(r)\n",
    "    return instances\n",
    "\n",
    "def inside_outside(training_sents, grammar, start_sym='[E]'):\n",
    "    f = defaultdict(float)\n",
    "    for sent in training_sents:\n",
    "        forest = cky(grammar, sent)\n",
    "        goal = make_symbol(start_sym, 0, len(sent))\n",
    "        I = inside(forest, goal)\n",
    "        O = outside(forest, goal, I)     \n",
    "        for rule in grammar:\n",
    "            w = 0.0\n",
    "            for instance in get_instances(rule, forest):\n",
    "                k = rule.prob\n",
    "                k *= O[instance.lhs]\n",
    "                for child in instance.rhs:\n",
    "                    try:\n",
    "                        alpha = I[child]\n",
    "                    except KeyError:\n",
    "                        # same solution as in outside\n",
    "                        alpha = 0.0\n",
    "                    k *= alpha\n",
    "                w += k\n",
    "            f[rule] += w/I[goal]\n",
    "    return f\n",
    "\n",
    "def EM(training_sents, grammar, n, start_sym='[E]', prin=False):\n",
    "    if prin == True:\n",
    "        print \"Initalized grammar:\\n{}\\n\".format(grammar)\n",
    "    step = 0\n",
    "    while step < n:\n",
    "        \n",
    "        # E-step\n",
    "        f = inside_outside(training_sents, grammar, start_sym=start_sym)\n",
    "                \n",
    "        #M-step\n",
    "        new_grammar = WCFG()\n",
    "        for rule in grammar:\n",
    "            new_prob = f[rule]/sum([f[r] for r in grammar.get(rule.lhs)])\n",
    "            new_grammar.add(Rule(rule.lhs, rule.rhs, new_prob))\n",
    "        \n",
    "        grammar = new_grammar\n",
    "        \n",
    "        step +=1   \n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NN] -> mouse (0.33)\n",
      "[NN] -> cat (0.33)\n",
      "[NN] -> dog (0.34)\n",
      "[JJ] -> big (0.5)\n",
      "[JJ] -> black (0.5)\n",
      "[DT] -> the (0.5)\n",
      "[DT] -> a (0.5)\n",
      "[NPBAR] -> [JJ] [NN] (0.5)\n",
      "[NPBAR] -> [JJ] [NPBAR] (0.5)\n",
      "[VP] -> [VB] [NP] (1.0)\n",
      "[S] -> [NP] [VP] (1.0)\n",
      "[VB] -> chased (0.5)\n",
      "[VB] -> ate (0.5)\n",
      "[NP] -> [DT] [NN] (0.5)\n",
      "[NP] -> [DT] [NPBAR] (0.5)\n",
      "defaultdict(<type 'float'>, {[NN] -> mouse (0.33): 135.94117647058815, [DT] -> the (0.5): 97.0, [VP] -> [VB] [NP] (1.0): 100.0, [JJ] -> black (0.5): 126.0, [NN] -> cat (0.33): 62.0, [NPBAR] -> [JJ] [NPBAR] (0.5): 234.0, [NN] -> dog (0.34): 140.0606060606061, [S] -> [NP] [VP] (1.0): 100.0, [JJ] -> big (0.5): 108.0, [NPBAR] -> [JJ] [NN] (0.5): 234.0, [DT] -> a (0.5): 103.0, [VB] -> chased (0.5): 52.0, [NP] -> [DT] [NN] (0.5): 200.0, [VB] -> ate (0.5): 48.0, [NP] -> [DT] [NPBAR] (0.5): 200.0})\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "print hdp_pcfg\n",
    "f = inside_outside(hdp_corpus, hdp_pcfg, start_sym='[S]')\n",
    "print f\n",
    "\n",
    "s = 0\n",
    "for sent in hdp_corpus:\n",
    "    s += sum(map(lambda x : x=='mouse', sent))\n",
    "print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T] -> [P] (0.301961046813)\n",
      "[T] -> [T] * [P] (0.331971218888)\n",
      "[T] -> [T] + [P] (0.366067734298)\n",
      "[E] -> [T] (0.320911968357)\n",
      "[E] -> [E] + [T] (0.338503601884)\n",
      "[E] -> [E] * [T] (0.340584429759)\n",
      "[P] -> a (1.0)\n",
      "\n",
      "\n",
      "[T] -> [P] (0.424384292978)\n",
      "[T] -> [T] * [P] (0.301117234145)\n",
      "[T] -> [T] + [P] (0.274498472878)\n",
      "[E] -> [T] (0.59958139455)\n",
      "[E] -> [E] + [T] (0.180606508201)\n",
      "[E] -> [E] * [T] (0.219812097249)\n",
      "[P] -> a (1.0)\n",
      "\n",
      "\n",
      "[T] -> [P] (0.424384292978)\n",
      "[T] -> [T] * [P] (0.301117234145)\n",
      "[T] -> [T] + [P] (0.274498472878)\n",
      "[E] -> [T] (0.59958139455)\n",
      "[E] -> [E] + [T] (0.180606508201)\n",
      "[E] -> [E] * [T] (0.219812097249)\n",
      "[P] -> a (1.0)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print init_grammar\n",
    "print '\\n'\n",
    "\n",
    "f = inside_outside(corpus1, init_grammar, start_sym='[E]')\n",
    "\n",
    "new_grammar = WCFG()\n",
    "for rule in init_grammar:\n",
    "    new_prob = f[rule]/sum([f[r] for r in init_grammar.get(rule.lhs)])\n",
    "    new_grammar.add(Rule(rule.lhs, rule.rhs, new_prob))\n",
    "print new_grammar\n",
    "print '\\n'\n",
    "\n",
    "f = inside_outside(corpus1, new_grammar, start_sym='[E]')\n",
    "\n",
    "newnew_grammar = WCFG()\n",
    "for rule in new_grammar:\n",
    "    new_prob = f[rule]/sum([f[r] for r in new_grammar.get(rule.lhs)])\n",
    "    newnew_grammar.add(Rule(rule.lhs, rule.rhs, new_prob))\n",
    "print newnew_grammar\n",
    "print '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SOMEHOW this does not work... Why?\n",
    "G = WCFG(read_grammar_rules(open('examples/ambiguous', 'r')))\n",
    "init_grammar = initialize(G)\n",
    "\n",
    "print G\n",
    "print '\\n'\n",
    "print init_grammar\n",
    "print '\\n'\n",
    "new_grammar = EM(corpus2, init_grammar, 1)\n",
    "print new_grammar\n",
    "print '\\n'\n",
    "new_new_grammar = EM(corpus2, new_grammar, 1)\n",
    "print new_new_grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting progress\n",
    "\n",
    "We use pyplot to show the progress in the parameter estimation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_EM(corpus, grammar, n, start_sym='[E]', init=False):\n",
    "    \n",
    "    d = defaultdict(list)\n",
    "    for rule in grammar: # save the true grammar probs\n",
    "        ruled = Rule(rule.lhs, rule.rhs, 1.0) # make sure the dict entries do not depend on the rule probs\n",
    "        d[ruled].append(rule.prob)\n",
    "    \n",
    "    if init == True:\n",
    "        grammar = initialize(grammar)\n",
    "    \n",
    "    i = 0\n",
    "#     while i < n:\n",
    "    for i in range(n):\n",
    "        print \"round {}\".format(i)\n",
    "        new_grammar = EM(corpus, grammar, 1, start_sym=start_sym, prin=False)\n",
    "        for rule in new_grammar:\n",
    "            ruled = Rule(rule.lhs, rule.rhs, 1.0)\n",
    "            d[ruled].append(rule.prob)\n",
    "#             print \"rule {0}, prob {1}, rule-prob {2}\".format(rule, d[ruled], rule.prob)\n",
    "        \n",
    "        grammar = WCFG()\n",
    "        for rule in new_grammar:\n",
    "            grammar.add(rule)\n",
    "#         grammar = new_grammar\n",
    "#         i += 1\n",
    "\n",
    "    colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', \n",
    "              'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "    i = 0\n",
    "    for rule, prob in d.iteritems():\n",
    "        plt.plot(range(n+1), prob, color=colors[i%len(colors)])\n",
    "        plt.plot(range(n+1), [prob[0]]*(n+1), '--', color=colors[i%len(colors)])\n",
    "        i += 1\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0\n",
      "round 1\n",
      "round 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIepHAXEfEghbuIiAcp3EVEPOj/A4tJcZ46UEkyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11520f650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_EM(corpus1, G, 3, init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NN] -> mouse (0.33)\n",
      "[NN] -> cat (0.33)\n",
      "[NN] -> dog (0.34)\n",
      "[JJ] -> big (0.5)\n",
      "[JJ] -> black (0.5)\n",
      "[DT] -> the (0.5)\n",
      "[DT] -> a (0.5)\n",
      "[NPBAR] -> [JJ] [NN] (0.5)\n",
      "[NPBAR] -> [JJ] [NPBAR] (0.5)\n",
      "[VP] -> [VB] [NP] (1.0)\n",
      "[S] -> [NP] [VP] (1.0)\n",
      "[VB] -> chased (0.5)\n",
      "[VB] -> ate (0.5)\n",
      "[NP] -> [DT] [NN] (0.5)\n",
      "[NP] -> [DT] [NPBAR] (0.5)\n",
      "round 0\n",
      "round 1\n",
      "round 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPDrn68/tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1160738d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hdp_pcfg = WCFG(read_grammar_rules(open('examples/hdp-pcfg-grammar', 'r')))\n",
    "print hdp_pcfg\n",
    "hdp_corpus = generate_corpus(hdp_pcfg, 100, start=('[S]',))\n",
    "\n",
    "plot_EM(hdp_corpus, hdp_pcfg, 3, start_sym='[S]', init=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on the grammar G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initalized grammar:\n",
      "[T] -> [P] (0.336767037132)\n",
      "[T] -> [T] * [P] (0.249669565353)\n",
      "[T] -> [T] + [P] (0.413563397515)\n",
      "[E] -> [T] (0.383779381797)\n",
      "[E] -> [E] + [T] (0.269130910633)\n",
      "[E] -> [E] * [T] (0.34708970757)\n",
      "[P] -> a (1.0)\n",
      "\n",
      "[T] -> [P] (0.441357063964)\n",
      "[T] -> [T] * [P] (0.308400115141)\n",
      "[T] -> [T] + [P] (0.250242820895)\n",
      "[E] -> [T] (0.548605132613)\n",
      "[E] -> [E] + [T] (0.124257498849)\n",
      "[E] -> [E] * [T] (0.327137368539)\n",
      "[P] -> a (1.0)\n",
      "\n",
      "\n",
      "[T] -> [P] (0.5)\n",
      "[T] -> [T] * [P] (0.4)\n",
      "[T] -> [T] + [P] (0.1)\n",
      "[E] -> [T] (0.5)\n",
      "[E] -> [E] + [T] (0.45)\n",
      "[E] -> [E] * [T] (0.05)\n",
      "[P] -> a (1.0)\n"
     ]
    }
   ],
   "source": [
    "print EM(corpus1, init_grammar, 5)\n",
    "print '\\n'\n",
    "print G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital grammar:\n",
      "[T] -> [P] (0.332696712064)\n",
      "[T] -> [T] * [P] (0.395653638165)\n",
      "[T] -> [T] + [P] (0.271649649771)\n",
      "[E] -> [T] (0.281053698826)\n",
      "[E] -> [E] + [T] (0.327620451643)\n",
      "[E] -> [E] * [T] (0.391325849531)\n",
      "[P] -> a (1.0)\n",
      "\n",
      "[T] -> [P] (0.448748514495)\n",
      "[T] -> [T] * [P] (0.317777574063)\n",
      "[T] -> [T] + [P] (0.233473911442)\n",
      "[E] -> [T] (0.558221350963)\n",
      "[E] -> [E] + [T] (0.208759236296)\n",
      "[E] -> [E] * [T] (0.233019412741)\n",
      "[P] -> a (1.0)\n",
      "\n",
      "\n",
      "[T] -> [P] (0.5)\n",
      "[T] -> [T] * [P] (0.4)\n",
      "[T] -> [T] + [P] (0.1)\n",
      "[E] -> [T] (0.5)\n",
      "[E] -> [E] + [T] (0.45)\n",
      "[E] -> [E] * [T] (0.05)\n",
      "[P] -> a (1.0)\n"
     ]
    }
   ],
   "source": [
    "print EM(corpus2, init_grammar, 5)\n",
    "print '\\n'\n",
    "print G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on the NLTK toy-grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initalized grammar:\n",
      "[PP] -> [P] [NP] (1.0)\n",
      "[N] -> boy (0.213626231189)\n",
      "[N] -> cookie (0.251407938717)\n",
      "[N] -> table (0.173580173222)\n",
      "[N] -> telescope (0.154630860257)\n",
      "[N] -> hill (0.206754796615)\n",
      "[Det] -> the (0.280428681323)\n",
      "[Det] -> a (0.445360447257)\n",
      "[Det] -> my (0.27421087142)\n",
      "[V] -> saw (0.249916787884)\n",
      "[V] -> ate (0.297907226313)\n",
      "[V] -> ran (0.452175985803)\n",
      "[Name] -> Bob (0.481151564908)\n",
      "[Name] -> Jack (0.518848435092)\n",
      "[VP] -> [V] [NP] (0.32846516725)\n",
      "[VP] -> [V] (0.288795071913)\n",
      "[VP] -> [VP] [PP] (0.382739760838)\n",
      "[S] -> [NP] [VP] (1.0)\n",
      "[P] -> with (0.529596890353)\n",
      "[P] -> under (0.470403109647)\n",
      "[NP] -> [Det] [N] (0.407826990509)\n",
      "[NP] -> [Name] (0.36382543937)\n",
      "[NP] -> [NP] [PP] (0.228347570121)\n",
      "\n",
      "\n",
      "Approximated grammar:\n",
      "[PP] -> [P] [NP] (1.0)\n",
      "[N] -> boy (0.0361376056237)\n",
      "[N] -> cookie (0.0425288640327)\n",
      "[N] -> table (0.770175226412)\n",
      "[N] -> telescope (0.0)\n",
      "[N] -> hill (0.151158303931)\n",
      "[Det] -> the (0.571428571429)\n",
      "[Det] -> a (0.357142857143)\n",
      "[Det] -> my (0.0714285714286)\n",
      "[V] -> saw (0.314379275823)\n",
      "[V] -> ate (0.116812361341)\n",
      "[V] -> ran (0.568808362836)\n",
      "[Name] -> Bob (0.0341481572042)\n",
      "[Name] -> Jack (0.965851842796)\n",
      "[VP] -> [V] [NP] (0.238769143693)\n",
      "[VP] -> [V] (0.716307431079)\n",
      "[VP] -> [VP] [PP] (0.0449234252282)\n",
      "[S] -> [NP] [VP] (1.0)\n",
      "[P] -> with (0.461538461538)\n",
      "[P] -> under (0.538461538462)\n",
      "[NP] -> [Det] [N] (0.0463121696135)\n",
      "[NP] -> [Name] (0.66821844728)\n",
      "[NP] -> [NP] [PP] (0.285469383106)\n",
      "\n",
      "Original grammar:\n",
      "[PP] -> [P] [NP] (1.0)\n",
      "[N] -> boy (0.00807178839838)\n",
      "[N] -> cookie (0.0316565812866)\n",
      "[N] -> table (0.0570900947335)\n",
      "[N] -> telescope (0.0145962780072)\n",
      "[N] -> hill (0.888585257574)\n",
      "[VP] -> [V] [NP] (0.233315681274)\n",
      "[VP] -> [V] (0.756425771943)\n",
      "[VP] -> [VP] [PP] (0.0102585467832)\n",
      "[V] -> saw (0.676163237418)\n",
      "[V] -> ate (0.212617188137)\n",
      "[V] -> ran (0.111219574445)\n",
      "[Name] -> Bob (0.0505561321892)\n",
      "[Name] -> Jack (0.949443867811)\n",
      "[Det] -> the (0.590149092512)\n",
      "[Det] -> a (0.367025455096)\n",
      "[Det] -> my (0.0428254523922)\n",
      "[S] -> [NP] [VP] (1.0)\n",
      "[P] -> with (0.429341727392)\n",
      "[P] -> under (0.570658272608)\n",
      "[NP] -> [Det] [N] (0.0471285478774)\n",
      "[NP] -> [Name] (0.615695853153)\n",
      "[NP] -> [NP] [PP] (0.33717559897)\n",
      "\n",
      "Difference grammar:\n",
      "[PP] -> [P] [NP] (0.0)\n",
      "[N] -> boy (0.0280658172253)\n",
      "[N] -> cookie (0.010872282746)\n",
      "[N] -> table (0.713085131679)\n",
      "[N] -> telescope (0.0145962780072)\n",
      "[N] -> hill (0.737426953643)\n",
      "[VP] -> [V] [NP] (0.00545346241913)\n",
      "[VP] -> [V] (0.0401183408641)\n",
      "[VP] -> [VP] [PP] (0.034664878445)\n",
      "[V] -> saw (0.361783961595)\n",
      "[V] -> ate (0.095804826796)\n",
      "[V] -> ran (0.457588788391)\n",
      "[Name] -> Bob (0.016407974985)\n",
      "[Name] -> Jack (0.016407974985)\n",
      "[Det] -> the (0.0187205210831)\n",
      "[Det] -> a (0.00988259795327)\n",
      "[Det] -> my (0.0286031190364)\n",
      "[S] -> [NP] [VP] (0.0)\n",
      "[P] -> with (0.0321967341466)\n",
      "[P] -> under (0.0321967341466)\n",
      "[NP] -> [Det] [N] (0.000816378263907)\n",
      "[NP] -> [Name] (0.0525225941273)\n",
      "[NP] -> [NP] [PP] (0.0517062158634)\n"
     ]
    }
   ],
   "source": [
    "init_toy_grammar = initialize(toy_grammar)\n",
    "# print init_toy_grammar\n",
    "\n",
    "approx_grammar = EM(toy_corpus, init_toy_grammar, 1, start_sym='[S]', prin=True)\n",
    "print '\\nApproximated grammar:'\n",
    "print approx_grammar\n",
    "print '\\nOriginal grammar:'\n",
    "print toy_grammar\n",
    "\n",
    "def difference_grammar(one, another):\n",
    "    diff_grammar = WCFG()\n",
    "    for rule in one:\n",
    "        for r in another:\n",
    "            if r.rhs == rule.rhs and r.lhs == rule.lhs:\n",
    "                approx_prob = r.prob\n",
    "                break\n",
    "        diff_grammar.add(Rule(rule.lhs, rule.rhs, abs(rule.prob-approx_prob)))\n",
    "    return diff_grammar\n",
    "\n",
    "print '\\nDifference grammar:'\n",
    "print difference_grammar(toy_grammar, approx_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Counting derivations\n",
    "\n",
    "Another interesting question is\n",
    "\n",
    "* how many analyses of a given sentence do we have?\n",
    "\n",
    "This question is very simple to answer for acyclic hypergraphs and it turns out to be a special case of the inside recursion.\n",
    "\n",
    "        N(v) = \n",
    "            1                           if v is terminal\n",
    "            0                           if v is nonterminal and BS(v) is empty\n",
    "\n",
    "$$\\sum_{e \\in BS(v)} 1 * \\prod_{u \\in tail(e)} N(u)$$\n",
    "                                        otherwise\n",
    "                                        \n",
    "Compare the definition above with the inside recursion presented earlier.\n",
    "Also compare the program below with the inside computation and comment on the differences.\n",
    "\n",
    "Can you explain this recursion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counting(forest, start):  # acyclic hypergraph\n",
    "    N = dict()\n",
    "    \n",
    "    def get_count(symbol):\n",
    "        w = N.get(symbol, None)\n",
    "        if w is not None:\n",
    "            return w\n",
    "        incoming = forest.get(symbol, set())\n",
    "        if len(incoming) == 0:  # terminals have already been handled, this must be a nonterminal dead end\n",
    "            N[symbol] = w\n",
    "            return 0\n",
    "        w = 0\n",
    "        for rule in incoming:\n",
    "            k = 1\n",
    "            for child in rule.rhs:\n",
    "                k *= get_count(child)\n",
    "            w += k\n",
    "        N[symbol] = w\n",
    "        return w\n",
    "    \n",
    "    # handles terminals\n",
    "    for sym in forest.terminals:\n",
    "        N[sym] = 1\n",
    "    # handles nonterminals\n",
    "    #for sym in forest.nonterminals:\n",
    "    #    get_inside(sym)\n",
    "    get_count(start)\n",
    "        \n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = counting(forest, goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of derivations is associated with the value of N at the root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[goal]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi (best derivation)\n",
    "\n",
    "We might want to know which analysis score highest. That is,\n",
    "\n",
    "        d* = argmax_d p(x, d)\n",
    "        \n",
    "where d ranges over all possible derivations.\n",
    "\n",
    "Once we have computed inside weights, this is extremely simple to solve.\n",
    "However, we can also define a recursion which is specific for the computation of the Viterbi derivation. Do you think you can come up with its formula? Can you implement it?\n",
    "        \n",
    "        \n",
    "Below, an implementation based on inside weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "def viterbi(forest, I, start):\n",
    "    Q = deque([start])\n",
    "    d = []\n",
    "    while Q:\n",
    "        parent = Q.popleft()\n",
    "        incoming = forest.get(parent)\n",
    "        # here we will find the distribution over edges\n",
    "        weights = [0.0] * len(incoming)\n",
    "        for i, rule in enumerate(incoming):\n",
    "            weights[i] = rule.prob\n",
    "            for child in rule.rhs:\n",
    "                weights[i] *= I[child]\n",
    "        # here we select the edge that is the maximum of this distribution\n",
    "        weight, selected = max(zip(weights, incoming))\n",
    "        # we also need to queue the nonterminals in the tail of the edge\n",
    "        for sym in selected.rhs:\n",
    "            if is_nonterminal(sym):\n",
    "                Q.append(sym)\n",
    "        # and finally, add the selected edge to the derivation\n",
    "        d.append(selected)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[E:0-5] -> [E:0-1] + [T:2-5] (0.45),\n",
       " [E:0-1] -> [T:0-1] (0.5),\n",
       " [T:2-5] -> [T:2-3] * [P:4-5] (0.4),\n",
       " [T:0-1] -> [P:0-1] (0.5),\n",
       " [T:2-3] -> [P:2-3] (0.5),\n",
       " [P:4-5] -> a (1.0),\n",
       " [P:0-1] -> a (1.0),\n",
       " [P:2-3] -> a (1.0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = viterbi(forest, I, goal)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joint probability p(d, x) of the derivation is given by the product over its rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def joint_probability(d):\n",
    "    prob = 1.0\n",
    "    for rule in d:\n",
    "        prob *= rule.prob\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006250000000000001"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_probability(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional probability p(d|x) is given by\n",
    "\n",
    "    p(d|x) = p(d,x)/p(x)\n",
    "\n",
    "and we know that \n",
    "\n",
    "    p(x) = \\sum_d p(d,x)\n",
    "    \n",
    "is given by the inside at the root.\n",
    "\n",
    "Thus, the following is the conditional probability of the best derivation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6515837104072397"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_probability(d)/I[goal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can use this utilitary method to draw trees\n",
    "from util import make_nltk_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(E:0-5\n",
      "  (E:0-1 (T:0-1 (P:0-1 a)))\n",
      "  +\n",
      "  (T:2-5 (T:2-3 (P:2-3 a)) * (P:4-5 a)))\n"
     ]
    }
   ],
   "source": [
    "t = make_nltk_tree(d)\n",
    "print t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*the following will open a pop-up window and you need to find it ;)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "\n",
    "Often we are interested in drawing random samples from the distribution p(d|x).\n",
    "\n",
    "We can do that by sampling from the inverted CDF associated with p(d|x).\n",
    "The conditional independence assumption central to PCFGs make them convenient for sampling by *ancestral sampling*.\n",
    "\n",
    "The code below is very similar to the Viterbi code above, however, instead of maximising at each step, we draw a random edge from the distribution defined by their inside weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "def sample(forest, I, start):\n",
    "    Q = deque([start])\n",
    "    d = []\n",
    "    while Q:\n",
    "        parent = Q.popleft()\n",
    "        incoming = forest.get(parent)\n",
    "        # here we compute the distribution over edges\n",
    "        weights = [0.0] * len(incoming)\n",
    "        for i, rule in enumerate(incoming):\n",
    "            weights[i] = rule.prob\n",
    "            for child in rule.rhs:\n",
    "                weights[i] *= I[child]\n",
    "        # here we draw a random threshold (think of it as sampling from the inverted CDF)\n",
    "        th = random.uniform(0, I[parent])\n",
    "        # here we compute the CDF step by step and check\n",
    "        # for which edge e whether cdf(e) > th\n",
    "        total = 0.0\n",
    "        selected = None\n",
    "        back = None\n",
    "        for w, rule in zip(weights, incoming):\n",
    "            total += w\n",
    "            if total > th:\n",
    "                selected = rule\n",
    "                break\n",
    "            else:\n",
    "                back = rule\n",
    "        if selected is None:  # this is to deal with corner cases due to rounding problems\n",
    "            selected = back\n",
    "        # every nonterminal child of the selected edge must be added to the queue\n",
    "        for sym in selected.rhs:\n",
    "            if is_nonterminal(sym):\n",
    "                Q.append(sym)\n",
    "        d.append(selected)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we draw a random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[E:0-5] -> [T:0-5] (0.5),\n",
       " [T:0-5] -> [T:0-3] * [P:4-5] (0.4),\n",
       " [T:0-3] -> [T:0-1] + [P:2-3] (0.1),\n",
       " [P:4-5] -> a (1.0),\n",
       " [T:0-1] -> [P:0-1] (0.5),\n",
       " [P:2-3] -> a (1.0),\n",
       " [P:0-1] -> a (1.0)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(forest, I, goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical distribution\n",
    "\n",
    "A nice thing to do whe we can sample is to obtain an empirical distribution.\n",
    "That is, we draw a number of independent samples from the underlying distribution and approximate their probabilities by their relative frequency in the sample. The law of large numbers says that our estimates converge to true probabilities as we sample more. That also holds for expectations that we might want to compute based on the underlying distribution.\n",
    "\n",
    "Note how our estimates are pretty close to the true probabilities. This is because we are drawing indepent samples from the exact conditional distribution p(d|x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# n=633 prob=0.651583710407 estimate=0.633\n",
      "(E:0-5\n",
      "  (E:0-1 (T:0-1 (P:0-1 a)))\n",
      "  +\n",
      "  (T:2-5 (T:2-3 (P:2-3 a)) * (P:4-5 a)))\n",
      "\n",
      "# n=302 prob=0.289592760181 estimate=0.302\n",
      "(E:0-5 (T:0-5 (T:0-3 (T:0-1 (P:0-1 a)) + (P:2-3 a)) * (P:4-5 a)))\n",
      "\n",
      "# n=43 prob=0.0407239819005 estimate=0.043\n",
      "(E:0-5\n",
      "  (E:0-3 (E:0-1 (T:0-1 (P:0-1 a))) + (T:2-3 (P:2-3 a)))\n",
      "  *\n",
      "  (T:4-5 (P:4-5 a)))\n",
      "\n",
      "# n=22 prob=0.0180995475113 estimate=0.022\n",
      "(E:0-5\n",
      "  (E:0-3 (T:0-3 (T:0-1 (P:0-1 a)) + (P:2-3 a)))\n",
      "  *\n",
      "  (T:4-5 (P:4-5 a)))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# an example of how to estimate an empirical distribution out of 100 samples\n",
    "from collections import defaultdict\n",
    "counts = defaultdict(int)\n",
    "n_samples = 1000\n",
    "# here we sample a number of derivations\n",
    "for i in range(n_samples):\n",
    "    d = tuple(sample(forest, I, goal))\n",
    "    counts[d] += 1  # counting how often we they get sampled\n",
    "\n",
    "# here we sort them by frequency from most frequent to least frequent\n",
    "for d, n in sorted(counts.iteritems(), key=lambda (d, n): n, reverse=True):\n",
    "    # here we compute the exact probability (for comparison)\n",
    "    prob = joint_probability(d)/I[goal]\n",
    "    # here we compute an empirical estimate\n",
    "    estimate = float(n)/n_samples\n",
    "    t = make_nltk_tree(d)\n",
    "    print '# n=%d prob=%s estimate=%s\\n%s' % (n, prob, estimate, str(t))\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that our grammar, even though ambiguous, expresses a strong preference (a little over 65%) for the analysis that solves the product before the sum."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
